{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Language (Python) and SQL Querying for Data Science\n",
    "\n",
    "In this notebook, we'll explore Python programming and SQL querying concepts essential for data science. These are fundamental skills for any data scientist working with datasets like the Lending Club data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Python for Data Science](#python-for-data-science)\n",
    "2. [CRUD Operations in Python](#crud-operations-in-python)\n",
    "3. [Data Frame Operations](#data-frame-operations)\n",
    "4. [Table Operations in Python](#table-operations-in-python)\n",
    "5. [Match Operations](#match-operations)\n",
    "6. [Import/Export Operations](#importexport-operations)\n",
    "7. [Functions and Classes in Python](#functions-and-classes-in-python)\n",
    "8. [Object-Oriented Programming (OOP) in Python](#object-oriented-programming-oop-in-python)\n",
    "9. [SQL Querying for Data Science](#sql-querying-for-data-science)\n",
    "10. [SQL Use Cases in Data Science](#sql-use-cases-in-data-science)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create sample Lending Club dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "data = {\n",
    "    'loan_id': range(1, n_samples + 1),\n",
    "    'loan_amnt': np.random.normal(15000, 10000, n_samples),\n",
    "    'int_rate': np.random.normal(12, 4, n_samples),\n",
    "    'annual_inc': np.random.normal(75000, 30000, n_samples),\n",
    "    'dti': np.random.normal(15, 10, n_samples),\n",
    "    'fico_score': np.random.normal(700, 50, n_samples),\n",
    "    'emp_length': np.random.gamma(2, 2, n_samples),\n",
    "    'loan_status': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),\n",
    "    'grade': pd.cut(np.random.normal(700, 50, n_samples), \n",
    "                    bins=[0, 580, 620, 660, 700, 740, 780, 850], \n",
    "                    labels=['G', 'F', 'E', 'D', 'C', 'B', 'A']),\n",
    "    'home_ownership': np.random.choice(['MORTGAGE', 'RENT', 'OWN'], n_samples, p=[0.4, 0.3, 0.3]),\n",
    "    'purpose': np.random.choice(['debt_consolidation', 'credit_card', 'home_improvement', 'major_purchase', 'small_business'], \n",
    "                                n_samples, p=[0.3, 0.2, 0.2, 0.2, 0.1]),\n",
    "    'addr_state': np.random.choice(['CA', 'TX', 'NY', 'FL', 'IL', 'OH', 'GA', 'NC', 'MI', 'NJ'], n_samples),\n",
    "    'application_date': pd.date_range('2010-01-01', periods=n_samples, freq='H')[:n_samples]\n",
    "}\n",
    "\n",
    "# Ensure realistic values\n",
    "data['loan_amnt'] = np.abs(data['loan_amnt'])\n",
    "data['annual_inc'] = np.abs(data['annual_inc'])\n",
    "data['dti'] = np.abs(data['dti'])\n",
    "data['fico_score'] = np.clip(data['fico_score'], 300, 850)\n",
    "data['emp_length'] = np.clip(data['emp_length'], 0, 15)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Python and SQL for Data Science - Sample Lending Club Dataset\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset Shape: {df.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python for Data Science\n",
    "\n",
    "Python is one of the most popular programming languages for data science due to its simplicity, extensive libraries, and community support. Key features include:\n",
    "\n",
    "1. **Simplicity and Readability**: Easy to learn and use\n",
    "2. **Extensive Libraries**: NumPy, pandas, scikit-learn, matplotlib, seaborn\n",
    "3. **Community Support**: Large community and resources\n",
    "4. **Integration**: Easy integration with other tools and platforms\n",
    "5. **Open Source**: Free to use and contribute"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Python for Data Science - Libraries and Features\n",
    "\n",
    "print(\"Python Libraries for Data Science:\")\n",
    "print(\"\\n1. Data Manipulation:\")\n",
    "print(\"   - pandas: Data frames, data cleaning, transformation\")\n",
    "print(\"   - NumPy: Arrays, mathematical operations\")\n",
    "print(\"   - dplyr equivalent in Python: pandas operations\")\n",
    "\n",
    "print(\"\\n2. Visualization:\")\n",
    "print(\"   - matplotlib: Basic plotting\")\n",
    "print(\"   - seaborn: Statistical visualizations\")\n",
    "print(\"   - plotly: Interactive visualizations\")\n",
    "\n",
    "print(\"\\n3. Machine Learning:\")\n",
    "print(\"   - scikit-learn: Traditional ML algorithms\")\n",
    "print(\"   - tensorflow/keras: Deep learning\")\n",
    "print(\"   - xgboost/lightgbm: Gradient boosting\")\n",
    "\n",
    "print(\"\\n4. Deep Learning:\")\n",
    "print(\"   - PyTorch: Dynamic neural networks\")\n",
    "print(\"   - TensorFlow: Static neural networks\")\n",
    "\n",
    "print(\"\\n5. Data Access:\")\n",
    "print(\"   - SQLAlchemy: Database connections\")\n",
    "print(\"   - requests: API access\")\n",
    "\n",
    "# Demonstrate Python features with our dataset\n",
    "print(\"\\nPython Features Demonstration:\")\n",
    "\n",
    "# 1. Data types\n",
    "print(f\"\\n1. Data Types in our dataset:\")\n",
    "for col in df.columns:\n",
    "    print(f\"   {col}: {df[col].dtype}\")\n",
    "\n",
    "# 2. Data structures\n",
    "print(f\"\\n2. Data Structures:\")\n",
    "print(f\"   - Series example (first 5 fico_scores): {df['fico_score'].head().tolist()}\")\n",
    "print(f\"   - DataFrame shape: {df.shape}\")\n",
    "print(f\"   - Dictionary example: {{'mean_loan_amount': {df['loan_amnt'].mean():.2f}, 'count': {len(df)}}}\")\n",
    "\n",
    "# 3. Control structures\n",
    "print(f\"\\n3. Control Structures:\")\n",
    "high_fico_count = sum(1 for score in df['fico_score'] if score > 750)\n",
    "print(f\"   Count of loans with FICO > 750: {high_fico_count}\")\n",
    "\n",
    "# 4. List comprehension\n",
    "print(f\"\\n4. List Comprehension:\")\n",
    "high_risk_loans = [lid for lid, status in zip(df['loan_id'], df['loan_status']) if status == 1][:5]\n",
    "print(f\"   First 5 high-risk loan IDs: {high_risk_loans}\")\n",
    "\n",
    "# 5. Lambda functions\n",
    "print(f\"\\n5. Lambda Functions:\")\n",
    "df['risk_category'] = df['fico_score'].apply(lambda x: 'High Risk' if x < 600 else ('Medium Risk' if x < 700 else 'Low Risk'))\n",
    "print(f\"   Risk categories in data: {df['risk_category'].value_counts().to_dict()}\")\n",
    "\n",
    "# Visualize Python features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Distribution of risk categories\n",
    "risk_counts = df['risk_category'].value_counts()\n",
    "axes[0, 0].bar(risk_counts.index, risk_counts.values, color=['red', 'orange', 'green'])\n",
    "axes[0, 0].set_title('Distribution of Risk Categories')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# 2. Correlation heatmap\n",
    "corr_cols = ['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'fico_score', 'loan_status']\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Correlation Matrix')\n",
    "\n",
    "# 3. FICO Score by Grade\n",
    "fico_by_grade = df.groupby('grade')['fico_score'].mean().sort_values(ascending=False)\n",
    "axes[1, 0].bar(fico_by_grade.index, fico_by_grade.values, color=sns.color_palette(\"husl\", len(fico_by_grade)))\n",
    "axes[1, 0].set_title('Average FICO Score by Grade')\n",
    "axes[1, 0].set_ylabel('Average FICO Score')\n",
    "\n",
    "# 4. Loan Amount Distribution\n",
    "axes[1, 1].hist(df['loan_amnt'], bins=50, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "axes[1, 1].set_title('Loan Amount Distribution')\n",
    "axes[1, 1].set_xlabel('Loan Amount')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRUD Operations in Python\n",
    "\n",
    "CRUD operations (Create, Read, Update, Delete) are fundamental operations for database management. In Python, these operations can be performed using pandas DataFrames or with database connections."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CRUD Operations in Python\n",
    "\n",
    "print(\"CRUD Operations in Python with pandas:\")\n",
    "\n",
    "# 1. CREATE - Creating new data\n",
    "print(\"\\n1. CREATE Operations:\")\n",
    "\n",
    "# Create a subset of our data\n",
    "high_value_loans = df[df['loan_amnt'] > df['loan_amnt'].quantile(0.9)].copy()\n",
    "print(f\"   Created high-value loans dataset with {len(high_value_loans)} records\")\n",
    "\n",
    "# Add new calculated columns\n",
    "high_value_loans['loan_to_income_ratio'] = high_value_loans['loan_amnt'] / high_value_loans['annual_inc']\n",
    "high_value_loans['interest_cost'] = high_value_loans['loan_amnt'] * (high_value_loans['int_rate'] / 100)\n",
    "print(f\"   Added calculated columns: loan_to_income_ratio, interest_cost\")\n",
    "\n",
    "# 2. READ - Reading data\n",
    "print(\"\\n2. READ Operations:\")\n",
    "print(f\"   Reading dataset with shape: {high_value_loans.shape}\")\n",
    "print(f\"   Columns: {list(high_value_loans.columns)}\")\n",
    "print(f\"   Sample data:\")\n",
    "print(high_value_loans[['loan_id', 'loan_amnt', 'annual_inc', 'grade', 'loan_status']].head(3))\n",
    "\n",
    "# 3. UPDATE - Updating data\n",
    "print(\"\\n3. UPDATE Operations:\")\n",
    "\n",
    "# Update loan status based on FICO score for demonstration\n",
    "high_value_loans.loc[high_value_loans['fico_score'] > 750, 'loan_status'] = 0  # Set to 'paid' for high FICO\n",
    "updated_count = (high_value_loans['fico_score'] > 750).sum()\n",
    "print(f\"   Updated {updated_count} records based on FICO score\")\n",
    "print(f\"   Before update - Default rate: {(df[df['loan_amnt'] > df['loan_amnt'].quantile(0.9)]['loan_status'] == 1).mean():.2%}\")\n",
    "print(f\"   After update - Default rate: {(high_value_loans['loan_status'] == 1).mean():.2%}\")\n",
    "\n",
    "# 4. DELETE - Removing data\n",
    "print(\"\\n4. DELETE Operations:\")\n",
    "\n",
    "# Delete rows with missing critical values (though we don't have any in this simulated data)\n",
    "original_count = len(high_value_loans)\n",
    "high_value_loans = high_value_loans.dropna()  # This won't actually delete anything in our case\n",
    "print(f\"   Deleted records with missing values: {original_count - len(high_value_loans)} records deleted\")\n",
    "\n",
    "# Create another dataset for more complex CRUD operations\n",
    "customers_df = df[['loan_id', 'annual_inc', 'fico_score', 'home_ownership', 'addr_state']].copy()\n",
    "customers_df.columns = ['customer_id', 'income', 'credit_score', 'home_type', 'state']\n",
    "customers_df['customer_id'] = range(1, len(customers_df) + 1)\n",
    "\n",
    "loans_df = df[['loan_id', 'loan_amnt', 'int_rate', 'dti', 'loan_status']].copy()\n",
    "loans_df['customer_id'] = range(1, len(loans_df) + 1)\n",
    "\n",
    "# Demonstrate CRUD operations on customers and loans\n",
    "print(f\"\\nCRUD Operations on Customers and Loans:\")\n",
    "print(f\"   Customers table created with {len(customers_df)} customers\")\n",
    "print(f\"   Loans table created with {len(loans_df)} loans\")\n",
    "\n",
    "# CREATE: Add new customer\n",
    "new_customer = pd.DataFrame({\n",
    "    'customer_id': [len(customers_df) + 1],\n",
    "    'income': [80000],\n",
    "    'credit_score': [750],\n",
    "    'home_type': ['OWN'],\n",
    "    'state': ['WA']\n",
    "})\n",
    "customers_df = pd.concat([customers_df, new_customer], ignore_index=True)\n",
    "print(f\"   Created new customer record\")\n",
    "\n",
    "# READ: Filter customers\n",
    "high_income_customers = customers_df[customers_df['income'] > customers_df['income'].quantile(0.8)]\n",
    "print(f\"   Read {len(high_income_customers)} high-income customers\")\n",
    "\n",
    "# UPDATE: Update customer information\n",
    "customers_df.loc[customers_df['customer_id'] == 1, 'income'] = 90000\n",
    "print(f\"   Updated income for customer_id 1\")\n",
    "\n",
    "# DELETE: Remove customers with low credit score\n",
    "customers_df = customers_df[customers_df['credit_score'] >= 600]\n",
    "print(f\"   Deleted customers with credit score < 600\")\n",
    "print(f\"   Remaining customers: {len(customers_df)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frame Operations\n",
    "\n",
    "Data frames are central to data manipulation in Python. Pandas provides extensive functionality for data frame operations including selection, filtering, grouping, and aggregation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Data Frame Operations\n",
    "\n",
    "print(\"Data Frame Operations in Python:\")\n",
    "\n",
    "# 1. Selection Operations\n",
    "print(\"\\n1. Selection Operations:\")\n",
    "\n",
    "# Selecting columns\n",
    "selected_cols = df[['loan_amnt', 'fico_score', 'grade', 'loan_status']]\n",
    "print(f\"   Selected specific columns: {list(selected_cols.columns)}\")\n",
    "\n",
    "# Selecting rows with boolean indexing\n",
    "high_fico_loans = df[df['fico_score'] > 750]\n",
    "print(f\"   Selected loans with FICO > 750: {len(high_fico_loans)} records\")\n",
    "\n",
    "# Selecting with loc and iloc\n",
    "first_10 = df.loc[:9, ['loan_id', 'loan_amnt', 'fico_score']]\n",
    "print(f\"   Used .loc to select first 10 rows: shape {first_10.shape}\")\n",
    "\n",
    "first_10_iloc = df.iloc[:10, [0, 1, 4]]\n",
    "print(f\"   Used .iloc to select first 10 rows by position: shape {first_10_iloc.shape}\")\n",
    "\n",
    "# 2. Filtering Operations\n",
    "print(\"\\n2. Filtering Operations:\")\n",
    "\n",
    "# Multiple conditions\n",
    "prime_loans = df[(df['fico_score'] > 700) & (df['dti'] < 20) & (df['loan_status'] == 0)]\n",
    "print(f\"   Filtered prime loans (good credit, low DTI, paid): {len(prime_loans)} records\")\n",
    "\n",
    "# Using query method\n",
    "high_risk_loans = df.query('fico_score < 650 and int_rate > 12')\n",
    "print(f\"   Used .query() for high-risk loans: {len(high_risk_loans)} records\")\n",
    "\n",
    "# Using isin for multiple values\n",
    "target_states = df[df['addr_state'].isin(['CA', 'NY', 'TX'])]\n",
    "print(f\"   Used .isin() for target states: {len(target_states)} records\")\n",
    "\n",
    "# 3. Grouping Operations\n",
    "print(\"\\n3. Grouping Operations:\")\n",
    "\n",
    "# Group by single column\n",
    "grade_summary = df.groupby('grade').agg({\n",
    "    'loan_amnt': ['mean', 'count'],\n",
    "    'int_rate': 'mean',\n",
    "    'loan_status': 'mean',\n",
    "    'fico_score': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"   Grade summary:\")\n",
    "print(grade_summary.head())\n",
    "\n",
    "# Group by multiple columns\n",
    "grade_purpose_summary = df.groupby(['grade', 'purpose']).agg({\n",
    "    'loan_amnt': 'mean',\n",
    "    'loan_status': 'mean',\n",
    "    'count': ('loan_id', 'size')\n",
    "}).round(2)\n",
    "\n",
    "print(f\"   Multi-level grouping (top 5):\\n{grade_purpose_summary.head()}\")\n",
    "\n",
    "# 4. Aggregation Operations\n",
    "print(\"\\n4. Aggregation Operations:\")\n",
    "\n",
    "# Custom aggregation functions\n",
    "def range_func(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "agg_results = df.groupby('grade').agg({\n",
    "    'loan_amnt': ['mean', 'std', range_func],\n",
    "    'fico_score': ['min', 'max', 'median'],\n",
    "    'loan_status': ['count', 'sum', 'mean']\n",
    "})\n",
    "\n",
    "print(\"   Custom aggregation: loan_amnt range, fico min/max/median, status stats\")\n",
    "print(agg_results.head())\n",
    "\n",
    "# 5. Transformation Operations\n",
    "print(\"\\n5. Transformation Operations:\")\n",
    "\n",
    "# Using transform to add group statistics\n",
    "df['grade_avg_loan'] = df.groupby('grade')['loan_amnt'].transform('mean')\n",
    "df['grade_loan_diff'] = df['loan_amnt'] - df['grade_avg_loan']\n",
    "print(\"   Added grade average loan amount and difference columns\")\n",
    "\n",
    "# 6. Join/Merge Operations\n",
    "print(\"\\n6. Join/Merge Operations:\")\n",
    "\n",
    "# Create additional dataframes to demonstrate joins\n",
    "borrower_info = df[['loan_id', 'annual_inc', 'emp_length', 'home_ownership']].copy()\n",
    "borrower_info.columns = ['loan_id', 'income', 'emp_len', 'home']\n",
    "\n",
    "loan_features = df[['loan_id', 'grade', 'purpose', 'int_rate']].copy()\n",
    "loan_features.columns = ['loan_id', 'grade', 'purpose', 'interest_rate']\n",
    "\n",
    "# Inner join\n",
    "joined_df = pd.merge(borrower_info, loan_features, on='loan_id', how='inner')\n",
    "print(f\"   Inner join result: {joined_df.shape}\")\n",
    "\n",
    "# Visualize data frame operations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Distribution of loan amounts by grade\n",
    "df.boxplot(column='loan_amnt', by='grade', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Loan Amount Distribution by Grade')\n",
    "axes[0, 0].set_xlabel('Grade')\n",
    "\n",
    "# 2. Average interest rate by grade and purpose\n",
    "pivot_data = df.pivot_table(index='grade', columns='purpose', values='int_rate', aggfunc='mean')\n",
    "sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='RdYlGn_r', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Interest Rate by Grade and Purpose')\n",
    "\n",
    "# 3. Loan-to-income ratio distribution\n",
    "df['loan_to_income'] = df['loan_amnt'] / df['annual_inc']\n",
    "axes[1, 0].hist(df['loan_to_income'], bins=50, alpha=0.7, color='lightgreen')\n",
    "axes[1, 0].set_title('Loan-to-Income Ratio Distribution')\n",
    "axes[1, 0].set_xlabel('Loan-to-Income Ratio')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# 4. Default rate by grade\n",
    "default_by_grade = df.groupby('grade')['loan_status'].mean()\n",
    "axes[1, 1].bar(default_by_grade.index, default_by_grade.values, \n",
    "               color=sns.color_palette(\"husl\", len(default_by_grade)))\n",
    "axes[1, 1].set_title('Default Rate by Grade')\n",
    "axes[1, 1].set_ylabel('Default Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Operations in Python\n",
    "\n",
    "Table operations in Python involve working with structured data, including operations like pivot tables, reshaping, and complex calculations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Table Operations in Python\n",
    "\n",
    "print(\"Table Operations in Python:\")\n",
    "\n",
    "# Create a comprehensive dataset for table operations\n",
    "table_df = df.copy()\n",
    "table_df['year'] = table_df['application_date'].dt.year\n",
    "table_df['month'] = table_df['application_date'].dt.month\n",
    "\n",
    "# 1. Pivot Table Operations\n",
    "print(\"\\n1. Pivot Table Operations:\")\n",
    "\n",
    "# Basic pivot table\n",
    "pivot1 = pd.pivot_table(table_df, \n",
    "                        values='loan_amnt', \n",
    "                        index='grade', \n",
    "                        columns='loan_status', \n",
    "                        aggfunc='mean',\n",
    "                        fill_value=0)\n",
    "print(\"   Basic pivot table: Average loan amount by grade and loan status\")\n",
    "print(pivot1)\n",
    "\n",
    "# Complex pivot table\n",
    "pivot2 = pd.pivot_table(table_df, \n",
    "                        values=['loan_amnt', 'int_rate'], \n",
    "                        index=['grade', 'purpose'], \n",
    "                        columns='year', \n",
    "                        aggfunc='mean',\n",
    "                        margins=True)\n",
    "print(f\"\\n   Complex pivot table shape: {pivot2.shape}\")\n",
    "\n",
    "# 2. Cross-tabulation\n",
    "print(\"\\n2. Cross-tabulation Operations:\")\n",
    "\n",
    "crosstab1 = pd.crosstab(table_df['grade'], table_df['loan_status'], margins=True)\n",
    "print(\"   Cross-tabulation: Grade vs Loan Status\")\n",
    "print(crosstab1)\n",
    "\n",
    "# Cross-tabulation with values\n",
    "crosstab2 = pd.crosstab(table_df['grade'], table_df['purpose'], values=table_df['loan_amnt'], aggfunc='mean')\n",
    "print(f\"\\n   Cross-tabulation with values: Grade vs Purpose (avg loan amount)\")\n",
    "print(crosstab2)\n",
    "\n",
    "# 3. Data reshaping\n",
    "print(\"\\n3. Data Reshaping Operations:\")\n",
    "\n",
    "# Melt operation\n",
    "melt_df = table_df[['grade', 'loan_amnt', 'int_rate', 'fico_score']].head(10)\n",
    "melted = pd.melt(melt_df, id_vars=['grade'], \n",
    "                 value_vars=['loan_amnt', 'int_rate', 'fico_score'],\n",
    "                 var_name='metric', value_name='value')\n",
    "print(\"   Melted data from wide to long format:\")\n",
    "print(melted.head(6))\n",
    "\n",
    "# 4. Table calculations and functions\n",
    "print(\"\\n4. Table Calculations:\")\n",
    "\n",
    "# Apply function across rows\n",
    "table_df['risk_score'] = table_df.apply(\n",
    "    lambda row: row['int_rate'] * 0.5 + (850 - row['fico_score']) * 0.3 + row['dti'] * 0.2, axis=1)\n",
    "print(\"   Added risk score calculated from multiple variables\")\n",
    "\n",
    "# Apply function across columns\n",
    "numeric_cols = ['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'fico_score']\n",
    "summary_stats = table_df[numeric_cols].apply(['mean', 'std', 'min', 'max'])\n",
    "print(f\"   Applied summary statistics function to numeric columns\")\n",
    "\n",
    "# 5. Ranking and sorting operations\n",
    "print(\"\\n5. Ranking and Sorting Operations:\")\n",
    "\n",
    "# Ranking within groups\n",
    "table_df['loan_rank_in_grade'] = table_df.groupby('grade')['loan_amnt'].rank(method='dense', ascending=False)\n",
    "print(\"   Added loan amount rank within each grade\")\n",
    "\n",
    "# Sorting\n",
    "sorted_df = table_df.sort_values(['grade', 'loan_amnt'], ascending=[True, False]).head(10)\n",
    "print(f\"   Sorted by grade and loan amount (top 10):\")\n",
    "print(sorted_df[['grade', 'loan_amnt', 'fico_score']].head())\n",
    "\n",
    "# 6. Window functions\n",
    "print(\"\\n6. Window Functions:\")\n",
    "\n",
    "# Rolling average (for time series)\n",
    "table_df = table_df.sort_values('application_date')\n",
    "table_df['loan_amount_ma30'] = table_df['loan_amnt'].rolling(window=30).mean()\n",
    "print(\"   Added 30-day rolling average of loan amounts\")\n",
    "\n",
    "# Cumulative sum\n",
    "table_df['cumulative_loan_amount'] = table_df['loan_amnt'].cumsum()\n",
    "print(\"   Added cumulative loan amount\")\n",
    "\n",
    "# Visualize table operations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Heatmap of default rates by grade and year\n",
    "default_by_grade_year = table_df.groupby(['year', 'grade'])['loan_status'].mean().unstack()\n",
    "sns.heatmap(default_by_grade_year, annot=True, fmt='.3f', cmap='RdYlGn_r', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Default Rate by Grade and Year')\n",
    "\n",
    "# 2. Distribution of risk scores\n",
    "axes[0, 1].hist(table_df['risk_score'], bins=50, alpha=0.7, color='lightcoral')\n",
    "axes[0, 1].set_title('Distribution of Calculated Risk Scores')\n",
    "axes[0, 1].set_xlabel('Risk Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# 3. Top loans by grade\n",
    "top_loans = table_df.groupby('grade').apply(lambda x: x.nlargest(5, 'loan_amnt')).reset_index(drop=True)\n",
    "top_loans_by_grade = top_loans.groupby('grade')['loan_amnt'].mean()\n",
    "axes[1, 0].bar(top_loans_by_grade.index, top_loans_by_grade.values, \n",
    "               color=sns.color_palette(\"husl\", len(top_loans_by_grade)))\n",
    "axes[1, 0].set_title('Average Amount of Top 5 Loans by Grade')\n",
    "axes[1, 0].set_ylabel('Average Loan Amount')\n",
    "\n",
    "# 4. Time series of cumulative loan amount\n",
    "sample_ts = table_df.head(100)  # Use subset for visualization\n",
    "axes[1, 1].plot(sample_ts['application_date'], sample_ts['cumulative_loan_amount'], color='purple')\n",
    "axes[1, 1].set_title('Cumulative Loan Amount Over Time (Sample)')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Cumulative Amount')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Operations\n",
    "\n",
    "Match operations in Python involve finding and comparing data across different datasets, using techniques like exact matching, fuzzy matching, and conditional matching."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Match Operations in Python\n",
    "\n",
    "print(\"Match Operations in Python:\")\n",
    "\n",
    "# Create sample datasets for matching operations\n",
    "loan_data = df[['loan_id', 'fico_score', 'annual_inc', 'grade', 'dti', 'purpose']].copy()\n",
    "loan_data.columns = ['loan_id', 'credit_score', 'income', 'grade', 'dti', 'purpose']\n",
    "\n",
    "# Create a second dataset with some matching and non-matching records\n",
    "borrower_data = df[['loan_id', 'home_ownership', 'emp_length', 'addr_state', 'application_date']].copy()\n",
    "borrower_data.columns = ['id', 'home_type', 'employment', 'state', 'app_date']\n",
    "borrower_data = borrower_data.head(4500)  # Use subset to create some unmatched records\n",
    "\n",
    "# 1. Exact Matching (Join Operations)\n",
    "print(\"\\n1. Exact Matching Operations:\")\n",
    "\n",
    "# Inner join - only matched records\n",
    "inner_match = pd.merge(loan_data, borrower_data, left_on='loan_id', right_on='id', how='inner')\n",
    "print(f\"   Inner join - matched records: {len(inner_match)}\")\n",
    "\n",
    "# Left join - all records from left with matched from right\n",
    "left_match = pd.merge(loan_data, borrower_data, left_on='loan_id', right_on='id', how='left')\n",
    "print(f\"   Left join - all left records: {len(left_match)}, unmatched from right: {len(left_match) - len(inner_match)}\")\n",
    "\n",
    "# 2. Conditional Matching\n",
    "print(\"\\n2. Conditional Matching Operations:\")\n",
    "\n",
    "# Create a rate card for matching interest rates based on credit score and grade\n",
    "rate_card = pd.DataFrame({\n",
    "    'min_fico': [300, 600, 650, 700, 750],\n",
    "    'max_fico': [599, 649, 699, 749, 850],\n",
    "    'grade_factor': [1.5, 1.2, 1.0, 0.8, 0.6],  # Multiplier based on grade\n",
    "    'base_rate': [18, 15, 12, 10, 8]\n",
    "})\n",
    "\n",
    "# Match conditions to assign expected interest rates\n",
    "def assign_expected_rate(row):\n",
    "    for idx, card_row in rate_card.iterrows():\n",
    "        if card_row['min_fico'] <= row['credit_score'] <= card_row['max_fico']:\n",
    "            # Apply grade factor\n",
    "            grade_factors = {'A': 0.6, 'B': 0.7, 'C': 0.9, 'D': 1.0, 'E': 1.2, 'F': 1.5, 'G': 1.8}\n",
    "            factor = grade_factors.get(row['grade'], 1.0)\n",
    "            return card_row['base_rate'] * factor\n",
    "    return 15.0  # Default rate\n",
    "\n",
    "loan_data['expected_rate'] = loan_data.apply(assign_expected_rate, axis=1)\n",
    "print(f\"   Assigned expected rates based on credit score and grade\")\n",
    "print(f\"   Sample matches:\\n{loan_data[['credit_score', 'grade', 'expected_rate']].head()}\")\n",
    "\n",
    "# 3. Fuzzy Matching\n",
    "print(\"\\n3. Fuzzy Matching Operations:\")\n",
    "\n",
    "# Simulate fuzzy matching with purpose categories\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Create a mapping of possible purpose variations\n",
    "standard_purposes = ['debt_consolidation', 'credit_card', 'home_improvement', 'major_purchase', 'small_business', 'other']\n",
    "loan_data['purpose_standardized'] = loan_data['purpose']\n",
    "\n",
    "# Simulate some alternative spellings for demonstration\n",
    "fuzzy_purpose_mapping = {\n",
    "    'debt consolidation': 'debt_consolidation',\n",
    "    'credit card': 'credit_card',\n",
    "    'home improvement': 'home_improvement',\n",
    "    'major purchase': 'major_purchase',\n",
    "    'small business': 'small_business'\n",
    "}\n",
    "print(\"   Demonstrated fuzzy matching concept for text standardization\")\n",
    "\n",
    "# 4. Isin/Match Operations\n",
    "print(\"\\n4. Isin/Match Operations:\")\n",
    "\n",
    "# Find loans that match specific criteria\n",
    "target_criteria = {\n",
    "    'high_value': loan_data['income'] > loan_data['income'].quantile(0.8),\n",
    "    'good_credit': loan_data['credit_score'] > 700,\n",
    "    'low_dti': loan_data['dti'] < 15\n",
    "}\n",
    "\n",
    "high_quality_loans = loan_data[\n",
    "    target_criteria['high_value'] & \n",
    "    target_criteria['good_credit'] & \n",
    "    target_criteria['low_dti']\n",
    "]\n",
    "print(f\"   Matched high-quality loans (high income, good credit, low DTI): {len(high_quality_loans)}\")\n",
    "\n",
    "# 5. Pattern Matching\n",
    "print(\"\\n5. Pattern Matching Operations:\")\n",
    "\n",
    "# Create categorical variables based on patterns\n",
    "loan_data['income_tier'] = pd.cut(loan_data['income'], \n",
    "                                  bins=[0, 40000, 70000, 100000, float('inf')],\n",
    "                                  labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "loan_data['risk_tier'] = pd.cut(loan_data['credit_score'], \n",
    "                                bins=[0, 600, 650, 700, 850],\n",
    "                                labels=['Very High Risk', 'High Risk', 'Medium Risk', 'Low Risk'])\n",
    "\n",
    "print(f\"   Created income and risk tiers based on patterns\")\n",
    "print(f\"   Income tier distribution: {loan_data['income_tier'].value_counts().to_dict()}\")\n",
    "print(f\"   Risk tier distribution: {loan_data['risk_tier'].value_counts().to_dict()}\")\n",
    "\n",
    "# 6. String Matching\n",
    "print(\"\\n6. String Matching Operations:\")\n",
    "\n",
    "# Create a sample dataset with string variations\n",
    "state_names = pd.DataFrame({\n",
    "    'state_code': ['CA', 'TX', 'NY', 'FL', 'IL', 'OH', 'GA', 'NC', 'MI', 'NJ'],\n",
    "    'state_full': ['California', 'Texas', 'New York', 'Florida', 'Illinois', \n",
    "                   'Ohio', 'Georgia', 'North Carolina', 'Michigan', 'New Jersey']\n",
    "})\n",
    "\n",
    "# Demonstrate string operations\n",
    "borrower_data['state_full'] = borrower_data['state'].map(dict(zip(state_names['state_code'], \n",
    "                                                                state_names['state_full'])))\n",
    "print(f\"   Mapped state codes to full names\")\n",
    "\n",
    "# Visualize match operations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Expected vs actual interest rates\n",
    "loan_data['actual_rate'] = df.head(len(loan_data))['int_rate'].values\n",
    "axes[0, 0].scatter(loan_data['expected_rate'], loan_data['actual_rate'], alpha=0.6)\n",
    "axes[0, 0].plot([loan_data['expected_rate'].min(), loan_data['expected_rate'].max()], \n",
    "                [loan_data['expected_rate'].min(), loan_data['expected_rate'].max()], 'r--', lw=2)\n",
    "axes[0, 0].set_title('Expected vs Actual Interest Rates')\n",
    "axes[0, 0].set_xlabel('Expected Rate')\n",
    "axes[0, 0].set_ylabel('Actual Rate')\n",
    "\n",
    "# 2. Distribution of matched high-quality loans\n",
    "high_quality_credit = high_quality_loans['credit_score']\n",
    "all_credit = loan_data['credit_score']\n",
    "axes[0, 1].hist([all_credit, high_quality_credit], bins=50, alpha=0.7, \n",
    "                label=['All Loans', 'High-Quality Loans'], color=['lightblue', 'orange'])\n",
    "axes[0, 1].set_title('Credit Score Distribution: All vs High-Quality Loans')\n",
    "axes[0, 1].set_xlabel('Credit Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Income tier vs risk tier\n",
    "crosstab_match = pd.crosstab(loan_data['income_tier'], loan_data['risk_tier'], normalize='index')\n",
    "sns.heatmap(crosstab_match, annot=True, fmt='.2%', cmap='RdYlGn_r', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Correspondence: Income Tier vs Risk Tier')\n",
    "\n",
    "# 4. Matched records by grade\n",
    "matched_by_grade = inner_match.groupby('grade').size()\n",
    "axes[1, 1].bar(matched_by_grade.index, matched_by_grade.values, \n",
    "               color=sns.color_palette(\"husl\", len(matched_by_grade)))\n",
    "axes[1, 1].set_title('Matched Records by Grade')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import/Export Operations\n",
    "\n",
    "Import/export operations are crucial for data science workflows, allowing data to be read from and written to various formats and sources."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import/Export Operations in Python\n",
    "\n",
    "print(\"Import/Export Operations in Python:\")\n",
    "\n",
    "# 1. Reading different file formats\n",
    "print(\"\\n1. Import (Reading) Operations:\")\n",
    "\n",
    "# We've already imported our main dataset using pd.read_csv\n",
    "# Now let's demonstrate other import methods\n",
    "\n",
    "# Create sample files for import/export demonstration\n",
    "import os\n",
    "import json\n",
    "\n",
    "# CSV export/import\n",
    "sample_data = df.head(100).copy()\n",
    "csv_path = 'sample_loans.csv'\n",
    "sample_data.to_csv(csv_path, index=False)\n",
    "print(f\"   Exported sample data to CSV: {csv_path}\")\n",
    "imported_csv = pd.read_csv(csv_path)\n",
    "print(f\"   Imported CSV data with shape: {imported_csv.shape}\")\n",
    "\n",
    "# JSON export/import\n",
    "json_path = 'sample_loans.json'\n",
    "sample_data.head(10).to_json(json_path, orient='records', indent=2)\n",
    "print(f\"   Exported sample data to JSON: {json_path}\")\n",
    "imported_json = pd.read_json(json_path)\n",
    "print(f\"   Imported JSON data with shape: {imported_json.shape}\")\n",
    "\n",
    "# Excel export/import\n",
    "excel_path = 'sample_loans.xlsx'\n",
    "sample_data.to_excel(excel_path, index=False, sheet_name='Loans')\n",
    "print(f\"   Exported sample data to Excel: {excel_path}\")\n",
    "imported_excel = pd.read_excel(excel_path)\n",
    "print(f\"   Imported Excel data with shape: {imported_excel.shape}\")\n",
    "\n",
    "# Parquet export/import (efficient columnar format)\n",
    "parquet_path = 'sample_loans.parquet'\n",
    "sample_data.to_parquet(parquet_path)\n",
    "print(f\"   Exported sample data to Parquet: {parquet_path}\")\n",
    "imported_parquet = pd.read_parquet(parquet_path)\n",
    "print(f\"   Imported Parquet data with shape: {imported_parquet.shape}\")\n",
    "\n",
    "# 2. Database operations\n",
    "print(\"\\n2. Database Import/Export Operations:\")\n",
    "\n",
    "# Create an SQLite database for demonstration\n",
    "db_path = 'lending_club.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Export to database\n",
    "small_sample = df.head(500)  # Use smaller sample for database\n",
    "small_sample.to_sql('loans', conn, if_exists='replace', index=False)\n",
    "print(f\"   Exported data to SQLite database: {db_path}\")\n",
    "\n",
    "# Import from database\n",
    "imported_db = pd.read_sql_query('SELECT * FROM loans WHERE grade = \"A\"', conn)\n",
    "print(f\"   Imported data from database (Grade A loans): {imported_db.shape}\")\n",
    "\n",
    "# Using SQLAlchemy for more advanced database operations\n",
    "engine = create_engine(f'sqlite:///{db_path}')\n",
    "sqlalchemy_data = pd.read_sql_table('loans', engine)\n",
    "print(f\"   Imported using SQLAlchemy: {sqlalchemy_data.shape}\")\n",
    "\n",
    "# 3. API Data Import\n",
    "print(\"\\n3. API Data Import Simulation:\")\n",
    "\n",
    "# Simulate API response data\n",
    "api_response = {\n",
    "    'loans': [\n",
    "        {'loan_id': 9999, 'loan_amount': 25000, 'interest_rate': 12.5, 'status': 'approved'},\n",
    "        {'loan_id': 10000, 'loan_amount': 18000, 'interest_rate': 9.8, 'status': 'approved'},\n",
    "        {'loan_id': 10001, 'loan_amount': 32000, 'interest_rate': 15.2, 'status': 'pending'}\n",
    "    ],\n",
    "    'metadata': {\n",
    "        'total_count': 3,\n",
    "        'fetched_at': '2023-12-10T10:00:00Z'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert API response to DataFrame\n",
    "api_df = pd.DataFrame(api_response['loans'])\n",
    "print(f\"   Simulated importing from API: {api_df.shape}\")\n",
    "print(f\"   API Data Sample:\\n{api_df.head()}\")\n",
    "\n",
    "# 4. Export with specific options\n",
    "print(\"\\n4. Export Operations with Options:\")\n",
    "\n",
    "# Export with specific formatting\n",
    "formatted_csv = 'formatted_loans.csv'\n",
    "export_data = df.head(20)[['loan_id', 'loan_amnt', 'int_rate', 'fico_score', 'grade', 'loan_status']]\n",
    "export_data.to_csv(formatted_csv, \n",
    "                   index=False,\n",
    "                   float_format='%.2f',\n",
    "                   date_format='%Y-%m-%d')\n",
    "print(f\"   Exported with formatting options: {formatted_csv}\")\n",
    "\n",
    "# Export to multiple sheets in Excel\n",
    "multi_sheet_path = 'multi_sheet_loans.xlsx'\n",
    "with pd.ExcelWriter(multi_sheet_path) as writer:\n",
    "    df[df['grade'] == 'A'].head(10).to_excel(writer, sheet_name='Grade_A', index=False)\n",
    "    df[df['grade'] == 'B'].head(10).to_excel(writer, sheet_name='Grade_B', index=False)\n",
    "    df[df['grade'] == 'C'].head(10).to_excel(writer, sheet_name='Grade_C', index=False)\n",
    "print(f\"   Exported to multi-sheet Excel: {multi_sheet_path}\")\n",
    "\n",
    "# 5. Handling different encodings\n",
    "print(\"\\n5. Handling Different Encodings:\")\n",
    "\n",
    # Create sample with special characters\n",
    "special_df = pd.DataFrame({\n",
    "    'id': [1, 2],\n",
    "    'description': ['Loan for café', 'Prêt personnel'],\n",
    "    'value': [1000.0, 1500.0]\n",
    "})\n",
    "\n",
    "special_df.to_csv('special_chars.csv', index=False, encoding='utf-8')\n",
    "read_special = pd.read_csv('special_chars.csv', encoding='utf-8')\n",
    "print(f\"   Exported/imported with UTF-8 encoding: {read_special.shape}\")\n",
    "\n",
    # 6. Export for specific use cases\n",
    "print(\"\\n6. Export for Specific Use Cases:\")\n",
    "\n",
    "# Export for machine learning modeling (feature matrix)\n",
    "ml_features = df[['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'fico_score', 'loan_status']].copy()\n",
    "ml_features.to_csv('ml_features.csv', index=False)\n",
    "print(f\"   Exported ML-ready features: ml_features.csv\")\n",
    "\n",
    "# Export summary statistics\n",
    "summary_stats = df.describe()\n",
    "summary_stats.to_csv('summary_statistics.csv')\n",
    "print(f\"   Exported summary statistics: summary_statistics.csv\")\n",
    "\n",
    "# Visualize the import/export process\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. File format comparison\n",
    "formats = ['CSV', 'JSON', 'Excel', 'Parquet']\n",
    "sizes = [os.path.getsize(f) if os.path.exists(f) else 0 for f in ['sample_loans.csv', 'sample_loans.json', 'sample_loans.xlsx', 'sample_loans.parquet']]\n",
    "sizes = [s/1024 for s in sizes]  # Convert to KB\n",
    "axes[0, 0].bar(formats, sizes, color=['#FF9999', '#66B2FF', '#99FF99', '#FFD700'])\n",
    "axes[0, 0].set_title('File Size Comparison (KB)')\n",
    "axes[0, 0].set_ylabel('Size (KB)')\n",
    "for i, v in enumerate(sizes):\n",
    "    axes[0, 0].text(i, v + max(sizes)*0.01, f'{v:.1f}', ha='center')\n",
    "\n",
    "# 2. Grade distribution in exported data\n",
    "grade_dist = sample_data['grade'].value_counts()\n",
    "axes[0, 1].pie(grade_dist.values, labels=grade_dist.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 1].set_title('Grade Distribution in Exported Sample')\n",
    "\n",
    # 3. Exported data characteristics\n",
    "axes[1, 0].scatter(imported_csv['fico_score'], imported_csv['int_rate'], alpha=0.6)\n",
    "axes[1, 0].set_title('Exported Data: FICO Score vs Interest Rate')\n",
    "axes[1, 0].set_xlabel('FICO Score')\n",
    "axes[1, 0].set_ylabel('Interest Rate')\n",
    "\n",
    # 4. Performance comparison visualization\n",
    "operations = ['Export CSV', 'Import CSV', 'Export DB', 'Import DB']\n",
    "time_estimates = [0.1, 0.15, 0.3, 0.25]  # Placeholder times in seconds\n",
    "axes[1, 1].bar(operations, time_estimates, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "axes[1, 1].set_title('Estimated Time for Import/Export Operations')\n",
    "axes[1, 1].set_ylabel('Time (seconds)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Clean up created files\n",
    "files_to_delete = [\n",
    "    'sample_loans.csv', 'sample_loans.json', 'sample_loans.xlsx', 'sample_loans.parquet',\n",
    "    'lending_club.db', 'formatted_loans.csv', 'multi_sheet_loans.xlsx',\n",
    "    'special_chars.csv', 'ml_features.csv', 'summary_statistics.csv'\n",
    "]\n",
    "\n",
    "for file in files_to_delete:\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except FileNotFoundError:\n",
    "        pass  # File might not have been created\n",
    "\n",
    "print(f\"\\nCleaned up {len(files_to_delete)} temporary files\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Classes in Python\n",
    "\n",
    "Functions and classes are fundamental to programming in Python, allowing for code reusability, organization, and abstraction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Functions and Classes in Python\n",
    "\n",
    "print(\"Functions and Classes in Python:\")\n",
    "\n",
    "# 1. Basic Functions\n",
    "def calculate_monthly_payment(loan_amount, interest_rate, term_months=36):\n",
    "    \"\"\"\n",
    "    Calculate monthly payment for a loan\n",
    "    \n",
    "    Args:\n",
    "        loan_amount (float): Principal amount\n",
    "        interest_rate (float): Annual interest rate in percentage\n",
    "        term_months (int): Loan term in months\n",
    "    \n",
    "    Returns:\n",
    "        float: Monthly payment amount\n",
    "    \"\"\"\n",
    "    monthly_rate = (interest_rate / 100) / 12\n",
    "    if monthly_rate == 0:  # Handle 0% interest\n",
    "        return loan_amount / term_months\n",
    "    else:\n",
    "        return loan_amount * (monthly_rate * (1 + monthly_rate)**term_months) / ((1 + monthly_rate)**term_months - 1)\n",
    "\n",
    "# 2. Function with multiple parameters and default values\n",
    "def assess_credit_risk(fico_score, dti_ratio, employment_length, annual_income):\n",
    "    \"\"\"\n",
    "    Assess credit risk based on multiple factors\n",
    "    \n",
    "    Returns:\n",
    "        dict: Risk level and score\n",
    "    \"\"\"\n",
    "    risk_score = 0\n",
    "    \n",
    "    # FICO score impact\n",
    "    if fico_score >= 750:\n",
    "        risk_score -= 30\n",
    "    elif fico_score >= 700:\n",
    "        risk_score -= 20\n",
    "    elif fico_score >= 650:\n",
    "        risk_score -= 10\n",
    "    else:\n",
    "        risk_score += 20\n",
    "    \n",
    "    # DTI impact\n",
    "    if dti_ratio <= 15:\n",
    "        risk_score -= 15\n",
    "    elif dti_ratio <= 25:\n",
    "        risk_score -= 5\n",
    "    else:\n",
    "        risk_score += 15\n",
    "    \n",
    "    # Employment impact\n",
    "    if employment_length >= 5:\n",
    "        risk_score -= 10\n",
    "    elif employment_length >= 2:\n",
    "        risk_score -= 5\n",
    "    else:\n",
    "        risk_score += 10\n",
    "    \n",
    "    # Income impact\n",
    "    if annual_income >= 100000:\n",
    "        risk_score -= 10\n",
    "    elif annual_income >= 75000:\n",
    "        risk_score -= 5\n",
    "    elif annual_income < 40000:\n",
    "        risk_score += 10\n",
    "    \n",
    "    # Determine risk level\n",
    "    if risk_score <= -25:\n",
    "        risk_level = \"Very Low\"\n",
    "    elif risk_score <= -10:\n",
    "        risk_level = \"Low\"\n",
    "    elif risk_score <= 10:\n",
    "        risk_level = \"Medium\"\n",
    "    elif risk_score <= 25:\n",
    "        risk_level = \"High\"\n",
    "    else:\n",
    "        risk_level = \"Very High\"\n",
    "    \n",
    "    return {\n",
    "        'risk_score': max(0, risk_score),  # Ensure non-negative\n",
    "        'risk_level': risk_level,\n",
    "        'approved': risk_score <= 15\n",
    "    }\n",
    "\n",
    "# 3. Lambda functions\n",
    "loan_to_income_ratio = lambda loan, income: loan / income if income > 0 else float('inf')\n",
    "fico_category = lambda score: 'Excellent' if score >= 750 else 'Good' if score >= 700 else 'Fair' if score >= 650 else 'Poor'\n",
    "\n",
    "# 4. Higher-order functions\n",
    "def apply_risk_model(data, risk_function):\n",
    "    \"\"\"\n",
    "    Apply a risk function to loan data\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for _, row in data.iterrows():\n",
    "        result = risk_function(\n",
    "            row['fico_score'],\n",
    "            row['dti'],\n",
    "            row['emp_length'],\n",
    "            row['annual_inc']\n",
    "        )\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "# Demonstrate functions\n",
    "print(\"\\n1. Function Examples:\")\n",
    "\n",
    "# Calculate monthly payment\n",
    "monthly_payment = calculate_monthly_payment(15000, 12.0, 36)\n",
    "print(f\"   Monthly payment for $15,000 loan at 12% for 36 months: ${monthly_payment:.2f}\")\n",
    "\n",
    "# Assess credit risk\n",
    "risk_result = assess_credit_risk(720, 18.5, 5.5, 80000)\n",
    "print(f\"   Credit risk assessment: {risk_result}\")\n",
    "\n",
    "# Use lambda functions\n",
    "ratio = loan_to_income_ratio(15000, 75000)\n",
    "category = fico_category(720)\n",
    "print(f\"   Loan-to-income ratio: {ratio:.3f}, FICO category: {category}\")\n",
    "\n",
    "# Apply risk model to sample data\n",
    "sample_risks = apply_risk_model(df.head(5), assess_credit_risk)\n",
    "print(f\"   Risk assessments for 5 loans: {[r['risk_level'] for r in sample_risks]}\")\n",
    "\n",
    "# 5. Classes for data science\n",
    "class LoanDataProcessor:\n",
    "    \"\"\"\n",
    "    A class for processing loan data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.original_data = data.copy()\n",
    "        self.processed_data = data.copy()\n",
    "        self.data_history = [\"Original data loaded\"]\n",
    "    \n",
    "    def clean_data(self):\n",
    "        \"\"\"Clean the data by removing invalid values\"\"\"\n",
    "        initial_count = len(self.processed_data)\n",
    "        \n",
    "        # Remove rows with negative values where not expected\n",
    "        self.processed_data = self.processed_data[self.processed_data['loan_amnt'] > 0]\n",
    "        self.processed_data = self.processed_data[self.processed_data['int_rate'] >= 0]\n",
    "        \n",
    "        removed_count = initial_count - len(self.processed_data)\n",
    "        self.data_history.append(f\"Removed {removed_count} rows with invalid values\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def add_features(self):\n",
    "        \"\"\"Add new calculated features\"\"\"\n",
    "        self.processed_data['loan_to_income_ratio'] = \\\n",
    "            self.processed_data['loan_amnt'] / (self.processed_data['annual_inc'] + 1)  # +1 to avoid division by 0\n",
    "        \n",
    "        self.processed_data['interest_cost'] = \\\n",
    "            self.processed_data['loan_amnt'] * (self.processed_data['int_rate'] / 100)\n",
    "        \n",
    "        self.processed_data['debt_to_asset_ratio'] = \\\n",
    "            self.processed_data['dti'] / (self.processed_data['fico_score'] / 100 + 1)\n",
    "        \n",
    "        self.data_history.append(\"Added 3 new calculated features\")\n",
    "        return self\n",
    "    \n",
    "    def filter_by_grade(self, grades):\n",
    "        \"\"\"Filter data by credit grade\"\"\"\n",
    "        initial_count = len(self.processed_data)\n",
    "        self.processed_data = self.processed_data[self.processed_data['grade'].isin(grades)]\n",
    "        filtered_count = initial_count - len(self.processed_data)\n",
    "        self.data_history.append(f\"Filtered to grades {grades}, removed {filtered_count} rows\")\n",
    "        return self\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get a summary of the data\"\"\"\n",
    "        summary = {\n",
    "            'shape': self.processed_data.shape,\n",
    "            'columns': list(self.processed_data.columns),\n",
    "            'history': self.data_history,\n",
    "            'default_rate': self.processed_data['loan_status'].mean() if 'loan_status' in self.processed_data.columns else 'N/A'\n",
    "        }\n",
    "        return summary\n",
    "    \n",
    "    def reset_to_original(self):\n",
    "        \"\"\"Reset processed data to original\"\"\"\n",
    "        self.processed_data = self.original_data.copy()\n",
    "        self.data_history = [\"Reset to original data\"]\n",
    "        return self\n",
    "\n",
    "# 6. Class with inheritance\n",
    "class CreditRiskModel(LoanDataProcessor):\n",
    "    \"\"\"\n",
    "    Extends LoanDataProcessor with credit risk modeling capabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "        self.risk_models = []\n",
    "    \n",
    "    def calculate_risk_scores(self):\n",
    "        \"\"\"Calculate risk scores using the assess_credit_risk function\"\"\"\n",
    "        risk_scores = []\n",
    "        for _, row in self.processed_data.iterrows():\n",
    "            risk_info = assess_credit_risk(\n",
    "                row['fico_score'],\n",
    "                row['dti'],\n",
    "                row['emp_length'],\n",
    "                row['annual_inc']\n",
    "            )\n",
    "            risk_scores.append(risk_info['risk_score'])\n",
    "        \n",
    "        self.processed_data['calculated_risk_score'] = risk_scores\n",
    "        self.data_history.append(\"Calculated risk scores for all loans\")\n",
    "        return self\n",
    "    \n",
    "    def get_risk_analysis(self):\n",
    "        \"\"\"Get risk analysis summary\"\"\"\n",
    "        if 'calculated_risk_score' not in self.processed_data.columns:\n",
    "            return \"Risk scores not calculated yet\"\n",
    "        \n",
    "        risk_summary = {\n",
    "            'avg_risk_score': self.processed_data['calculated_risk_score'].mean(),\n",
    "            'high_risk_threshold': self.processed_data['calculated_risk_score'].quantile(0.8),\n",
    "            'risk_distribution': pd.cut(self.processed_data['calculated_risk_score'], \n",
    "                                        bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']).value_counts().to_dict()\n",
    "        }\n",
    "        return risk_summary\n",
    "\n",
    "# Demonstrate classes\n",
    "print(\"\\n2. Class Examples:\")\n",
    "\n",
    "# Create and use LoanDataProcessor\n",
    "processor = LoanDataProcessor(df.head(1000))  # Use subset for demonstration\n",
    "summary_before = processor.get_summary()\n",
    "print(f\"   Initial data shape: {summary_before['shape']}\")\n",
    "\n",
    "# Chain operations\n",
    "processor.clean_data().add_features().filter_by_grade(['A', 'B', 'C'])\n",
    "summary_after = processor.get_summary()\n",
    "print(f\"   Final data shape after processing: {summary_after['shape']}\")\n",
    "print(f\"   Processing history: {summary_after['history']}\")\n",
    "\n",
    "# Create and use CreditRiskModel\n",
    "risk_model = CreditRiskModel(df.head(500))  # Use smaller subset\n",
    "risk_model.clean_data().add_features().calculate_risk_scores()\n",
    "risk_analysis = risk_model.get_risk_analysis()\n",
    "print(f\"\\n   Risk Analysis:\")\n",
    "print(f\"     Average Risk Score: {risk_analysis['avg_risk_score']:.2f}\")\n",
    "print(f\"     High Risk Threshold (80th percentile): {risk_analysis['high_risk_threshold']:.2f}\")\n",
    "print(f\"     Risk Distribution: {risk_analysis['risk_distribution']}\")\n",
    "\n",
    "# 7. Decorators for functions\n",
    "def timing_decorator(func):\n",
    "    \"\"\"Decorator to time function execution\"\"\"\n",
    "    import time\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"   {func.__name__} took {end - start:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timing_decorator\n",
    "def process_large_dataset(data):\n",
    "    \"\"\"Simulate processing a large dataset\"\"\"\n",
    "    # Add a calculated column\n",
    "    result = data.copy()\n",
    "    result['new_feature'] = result['loan_amnt'] / (result['fico_score'] + 1) * result['int_rate']\n",
    "    # Perform a groupby operation\n",
    "    avg_by_grade = result.groupby('grade')['new_feature'].mean()\n",
    "    return avg_by_grade\n",
    "\n",
    "# Use decorated function\n",
    "print(f\"\\n3. Decorator Example:\")\n",
    "avg_features = process_large_dataset(df.head(10000))\n",
    "print(f\"   Average new feature by grade:\\n{avg_features}\")\n",
    "\n",
    "# 8. Generator functions\n",
    "def loan_chunk_generator(data, chunk_size=100):\n",
    "    \"\"\"Generator to process data in chunks\"\"\"\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data.iloc[i:i + chunk_size]\n",
    "\n",
    "print(f\"\\n4. Generator Example:\")\n",
    "chunk_count = 0\n",
    "for chunk in loan_chunk_generator(df, 500):\n",
    "    chunk_count += 1\n",
    "    if chunk_count <= 3:  # Show first 3 chunks\n",
    "        print(f\"   Chunk {chunk_count}: {len(chunk)} loans\")\n",
    "print(f\"   Total chunks created: {chunk_count}\")\n",
    "\n",
    "# Visualize function and class usage\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Risk score distribution\n",
    "if 'calculated_risk_score' in risk_model.processed_data.columns:\n",
    "    axes[0, 0].hist(risk_model.processed_data['calculated_risk_score'], bins=30, alpha=0.7, color='skyblue')\n",
    "    axes[0, 0].set_title('Distribution of Calculated Risk Scores')\n",
    "    axes[0, 0].set_xlabel('Risk Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "else:\n",
    "    axes[0, 0].text(0.5, 0.5, 'Risk scores not calculated', \n",
    "                    horizontalalignment='center', verticalalignment='center',\n",
    "                    transform=axes[0, 0].transAxes)\n",
    "    axes[0, 0].set_title('Distribution of Calculated Risk Scores')\n",
    "\n",
    "# 2. Feature engineering results\n",
    "if 'loan_to_income_ratio' in processor.processed_data.columns:\n",
    "    axes[0, 1].scatter(processor.processed_data['fico_score'], \n",
    "                      processor.processed_data['loan_to_income_ratio'], alpha=0.6)\n",
    "    axes[0, 1].set_title('FICO Score vs Loan-to-Income Ratio')\n",
    "    axes[0, 1].set_xlabel('FICO Score')\n",
    "    axes[0, 1].set_ylabel('Loan-to-Income Ratio')\n",
    "else:\n",
    "    axes[0, 1].text(0.5, 0.5, 'Features not added', \n",
    "                    horizontalalignment='center', verticalalignment='center',\n",
    "                    transform=axes[0, 1].transAxes)\n",
    "    axes[0, 1].set_title('FICO Score vs Loan-to-Income Ratio')\n",
    "\n",
    "# 3. Monthly payment calculation\n",
    "loan_amounts = [10000, 15000, 20000, 25000, 30000]\n",
    "interest_rates = [8, 10, 12, 15, 18]\n",
    "monthly_payments = [calculate_monthly_payment(la, ir, 36) for la, ir in zip(loan_amounts, interest_rates)]\n",
    "axes[1, 0].bar([f'${la}, {ir}%' for la, ir in zip(loan_amounts, interest_rates)], monthly_payments, \n",
    "               color=sns.color_palette(\"husl\", len(monthly_payments)))\n",
    "axes[1, 0].set_title('Monthly Payments for Different Loan Scenarios')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Credit risk categories\n",
    "sample_fico_scores = df['fico_score'].sample(500)\n",
    "categories = [fico_category(score) for score in sample_fico_scores]\n",
    "category_counts = pd.Series(categories).value_counts()\n",
    "axes[1, 1].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 1].set_title('Distribution of FICO Score Categories')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-Oriented Programming (OOP) in Python\n",
    "\n",
    "Object-oriented programming is a programming paradigm based on the concept of \"objects\", which can contain data and code: data in the form of fields (often known as attributes or properties), and code, in the form of procedures (often known as methods)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Object-Oriented Programming (OOP) in Python\n",
    "\n",
    "print(\"Object-Oriented Programming (OOP) in Python:\")\n",
    "\n",
    "# 1. Basic Class Structure\n",
    "class Loan:\n",
    "    \"\"\"\n",
    "    A basic Loan class representing a loan product\n",
    "    \"\"\"\n",
    "    \n",
    "    # Class variable - shared by all instances\n",
    "    interest_rate_adjustment = 0.0  # Could be used for market adjustments\n",
    "    \n",
    "    def __init__(self, loan_id, amount, interest_rate, term_months, credit_score):\n",
    "        # Instance variables - unique to each instance\n",
    "        self.loan_id = loan_id\n",
    "        self.amount = amount\n",
    "        self.interest_rate = interest_rate\n",
    "        self.term_months = term_months\n",
    "        self.credit_score = credit_score\n",
    "        self.status = 'pending'  # Default status\n",
    "        \n",
    "        # Calculate monthly payment\n",
    "        self.monthly_payment = self.calculate_monthly_payment()\n",
    "    \n",
    "    def calculate_monthly_payment(self):\n",
    "        \"\"\"Calculate the monthly payment for the loan\"\"\"\n",
    "        monthly_rate = (self.interest_rate / 100) / 12\n",
    "        if monthly_rate == 0:\n",
    "            return self.amount / self.term_months\n",
    "        else:\n",
    "            return self.amount * (monthly_rate * (1 + monthly_rate)**self.term_months) / ((1 + monthly_rate)**self.term_months - 1)\n",
    "    \n",
    "    def approve_loan(self):\n",
    "        \"\"\"Approve the loan\"\"\"\n",
    "        if self.credit_score >= 650:\n",
    "            self.status = 'approved'\n",
    "            return True\n",
    "        else:\n",
    "            self.status = 'rejected'\n",
    "            return False\n",
    "    \n",
    "    def get_loan_summary(self):\n",
    "        \"\"\"Return a summary of the loan details\"\"\"\n",
    "        return {\n",
    "            'loan_id': self.loan_id,\n",
    "            'amount': self.amount,\n",
    "            'interest_rate': self.interest_rate,\n",
    "            'term_months': self.term_months,\n",
    "            'credit_score': self.credit_score,\n",
    "            'monthly_payment': self.monthly_payment,\n",
    "            'status': self.status\n",
    "        }\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"String representation of the loan\"\"\"\n",
    "        return f\"Loan {self.loan_id}: ${self.amount:,.2f} at {self.interest_rate}% (~${self.monthly_payment:.2f}/mo)\"\n",
    "\n",
    "# 2. Inheritance Example\n",
    "class PersonalLoan(Loan):\n",
    "    \"\"\"\n",
    "    A subclass of Loan for personal loans\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, loan_id, amount, interest_rate, term_months, credit_score, purpose):\n",
    "        super().__init__(loan_id, amount, interest_rate, term_months, credit_score)\n",
    "        self.purpose = purpose\n",
    "        self.max_amount = 50000  # Maximum amount for personal loans\n",
    "    \n",
    "    def approve_loan(self):\n",
    "        # Override parent method with additional checks\n",
    "        if self.amount > self.max_amount:\n",
    "            self.status = 'rejected - amount too high'\n",
    "            return False\n",
    "        \n",
    "        # Use parent logic for credit check\n",
    "        return super().approve_loan()\n",
    "    \n",
    "    def get_loan_summary(self):\n",
    "        # Extend parent method\n",
    "        summary = super().get_loan_summary()\n",
    "        summary['purpose'] = self.purpose\n",
    "        return summary\n",
    "\n",
    "class Mortgage(Loan):\n",
    "    \"\"\"\n",
    "    A subclass of Loan for mortgages\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, loan_id, amount, interest_rate, term_months, credit_score, down_payment_percent):\n",
    "        super().__init__(loan_id, amount, interest_rate, term_months, credit_score)\n",
    "        self.down_payment_percent = down_payment_percent\n",
    "        self.property_value = self.amount / (1 - down_payment_percent/100)\n",
    "    \n",
    "    def calculate_monthly_payment(self):\n",
    "        # Override parent method for mortgage-specific calculation\n",
    "        monthly_rate = (self.interest_rate / 100) / 12\n",
    "        if monthly_rate == 0:\n",
    "            return self.amount / self.term_months\n",
    "        else:\n",
    "            return self.amount * (monthly_rate * (1 + monthly_rate)**self.term_months) / ((1 + monthly_rate)**self.term_months - 1)\n",
    "    \n",
    "    def get_loan_summary(self):\n",
    "        # Override parent method with mortgage-specific info\n",
    "        summary = super().get_loan_summary()\n",
    "        summary['down_payment_percent'] = self.down_payment_percent\n",
    "        summary['property_value'] = self.property_value\n",
    "        return summary\n",
    "\n",
    "# 3. Encapsulation Example\n",
    "class LoanPortfolio:\n",
    "    \"\"\"\n",
    "    A class to manage a portfolio of loans with encapsulated data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._loans = []  # Protected attribute\n",
    "        self.__loan_count = 0  # Private attribute\n",
    "    \n",
    "    def add_loan(self, loan):\n",
    "        \"\"\"Add a loan to the portfolio\"\"\"\n",
    "        self._loans.append(loan)\n",
    "        self.__loan_count += 1\n",
    "    \n",
    "    def get_total_amount(self):\n",
    "        \"\"\"Calculate total amount of all loans\"\"\"\n",
    "        return sum(loan.amount for loan in self._loans)\n",
    "    \n",
    "    def get_portfolio_summary(self):\n",
    "        \"\"\"Get summary statistics for the portfolio\"\"\"\n",
    "        if not self._loans:\n",
    "            return {\"message\": \"Portfolio is empty\"}\n",
    "        \n",
    "        total_amount = self.get_total_amount()\n",
    "        avg_interest = sum(loan.interest_rate for loan in self._loans) / len(self._loans)\n",
    "        avg_credit_score = sum(loan.credit_score for loan in self._loans) / len(self._loans)\n",
    "        \n",
    "        return {\n",
    "            \"total_loans\": len(self._loans),\n",
    "            \"total_amount\": total_amount,\n",
    "            \"average_amount\": total_amount / len(self._loans),\n",
    "            \"average_interest_rate\": avg_interest,\n",
    "            \"average_credit_score\": avg_credit_score,\n",
    "            \"portfolio_count\": self.__loan_count\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Enable len() function on the portfolio\"\"\"\n",
    "        return len(self._loans)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Enable iteration over loans\"\"\"\n",
    "        return iter(self._loans)\n",
    "\n",
    "# 4. Polymorphism Example\n",
    "class RiskEvaluator:\n",
    "    \"\"\"\n",
    "    A class that demonstrates polymorphism through different loan types\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate_risk(loan):\n",
    "        \"\"\"Evaluate risk differently based on loan type\"\"\"\n",
    "        if isinstance(loan, Mortgage):\n",
    "            # Mortgages have additional risk factors\n",
    "            risk_score = loan.interest_rate * 0.7 + (850 - loan.credit_score) * 0.3\n",
    "            if loan.down_payment_percent < 20:\n",
    "                risk_score += 10  # Higher risk for low down payment\n",
    "        elif isinstance(loan, PersonalLoan):\n",
    "            # Personal loans have different risk factors\n",
    "            risk_score = loan.interest_rate * 0.8 + (850 - loan.credit_score) * 0.2\n",
    "            if loan.purpose == 'debt_consolidation':\n",
    "                risk_score += 5  # Slightly higher risk\n",
    "        else:\n",
    "            # Default loan evaluation\n",
    "            risk_score = loan.interest_rate * 0.9 + (850 - loan.credit_score) * 0.1\n",
    "        \n",
    "        return {\n",
    "            'loan_id': loan.loan_id,\n",
    "            'risk_score': risk_score,\n",
    "            'risk_level': 'High' if risk_score > 30 else 'Medium' if risk_score > 20 else 'Low'\n",
    "        }\n",
    "\n",
    "# Demonstrate OOP concepts\n",
    "print(\"\\n1. Basic Class Usage:\")\n",
    "\n",
    "# Create loan instances\n",
    "loan1 = Loan(1, 15000, 12.0, 36, 720)\n",
    "loan2 = Loan(2, 25000, 9.5, 60, 780)\n",
    "loan3 = PersonalLoan(3, 12000, 15.0, 36, 620, 'debt_consolidation')\n",
    "loan4 = Mortgage(4, 200000, 4.5, 360, 750, 20)\n",
    "\n",
    "print(f\"   {loan1}\")\n",
    "print(f\"   {loan2}\")\n",
    "print(f\"   {loan3}\")\n",
    "print(f\"   {loan4}\")\n",
    "\n",
    # Approve loans\n",
    "loan1.approve_loan()\n",
    "loan3.approve_loan()  # This may be rejected due to low credit score\n",
    "print(f\"   Loan 1 status: {loan1.status}\")\n",
    "print(f\"   Loan 3 status: {loan3.status}\")\n",
    "\n",
    "print(\"\\n2. Inheritance - Subclass Usage:\")\n",
    "print(f\"   Personal Loan Summary: {loan3.get_loan_summary()}\")\n",
    "print(f\"   Mortgage Summary: {loan4.get_loan_summary()}\")\n",
    "\n",
    "print(\"\\n3. Encapsulation - Portfolio Management:\")\n",
    "\n",
    "# Create a portfolio and add loans\n",
    "portfolio = LoanPortfolio()\n",
    "portfolio.add_loan(loan1)\n",
    "portfolio.add_loan(loan2)\n",
    "portfolio.add_loan(loan3)\n",
    "portfolio.add_loan(loan4)\n",
    "\n",
    # Get portfolio summary\n",
    "portfolio_summary = portfolio.get_portfolio_summary()\n",
    "print(f\"   Portfolio Summary: {portfolio_summary}\")\n",
    "\n",
    # Demonstrate encapsulation\n",
    "print(f\"   Number of loans (using len): {len(portfolio)}\")\n",
    "\n",
    "print(\"\\n4. Polymorphism - Risk Evaluation:\")\n",
    "\n",
    "# Evaluate risk for different loan types\n",
    "for loan in [loan1, loan3, loan4]:\n",
    "    risk_info = RiskEvaluator.evaluate_risk(loan)\n",
    "    print(f\"   {loan.loan_id} ({type(loan).__name__}): Risk = {risk_info['risk_score']:.2f}, Level = {risk_info['risk_level']}\")\n",
    "\n",
    "# 5. Data Classes (Python 3.7+) for simple data containers\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LoanApplication:\n",
    "    \"\"\"Data class for loan applications\"\"\"\n",
    "    applicant_id: int\n",
    "    loan_amount: float\n",
    "    credit_score: int\n",
    "    annual_income: float\n",
    "    requested_rate: float = 10.0\n",
    "    approved: bool = False\n",
    "    \n",
    "    def calculate_max_affordable(self):\n",
    "        \"\"\"Calculate maximum affordable loan based on income\"\"\"\n",
    "        # Generally, DTI should be <36%, so loan payment should be <25% of monthly income\n",
    "        monthly_income = self.annual_income / 12\n",
    "        max_monthly_payment = monthly_income * 0.25\n",
    "        \n",
    "        # Simple calculation\n",
    "        return max_monthly_payment * 36  # Assuming 36-month term\n",
    "\n",
    "# Use data class\n",
    "application = LoanApplication(1001, 15000, 720, 75000, 11.5)\n",
    "print(f\"\\n5. Data Class Example:\")\n",
    "print(f\"   Loan Application: {application}\")\n",
    "print(f\"   Max affordable loan: ${application.calculate_max_affordable():.2f}\")\n",
    "\n",
    "# 6. Context Managers\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def loan_analysis_session(data):\n",
    "    \"\"\"Context manager for loan analysis sessions\"\"\"\n",
    "    print(\"   Starting loan analysis session...\")\n",
    "    original_shape = data.shape\n",
    "    try:\n",
    "        yield data\n",
    "    finally:\n",
    "        print(f\"   Completed analysis. Original shape: {original_shape}, Final shape: {data.shape}\")\n",
    "\n",
    "print(f\"\\n6. Context Manager Example:\")\n",
    "with loan_analysis_session(df.head(100).copy()) as analysis_data:\n",
    "    # Perform operations\n",
    "    analysis_data['risk_category'] = analysis_data['fico_score'].apply(\n",
    "        lambda x: 'Low' if x >= 700 else 'High'\n",
    "    )\n",
    "    print(f\"   Analyzed {len(analysis_data)} loans and added risk categories\")\n",
    "\n",
    "# Visualize OOP concepts\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Loan amounts by type\n",
    "loan_types = ['Standard', 'Personal', 'Mortgage']\n",
    "loan_amounts = [loan1.amount, loan3.amount, loan4.amount]\n",
    "axes[0, 0].bar(loan_types, loan_amounts, color=['blue', 'green', 'red'])\n",
    "axes[0, 0].set_title('Loan Amounts by Type')\n",
    "axes[0, 0].set_ylabel('Amount ($)', color='black')\n",
    "# Add value labels\n",
    "for i, v in enumerate(loan_amounts):\n",
    "    axes[0, 0].text(i, v + max(loan_amounts)*0.01, f'${v:,.0f}', ha='center')\n",
    "\n",
    "# 2. Risk scores distribution\n",
    "risk_scores = [RiskEvaluator.evaluate_risk(loan)['risk_score'] for loan in [loan1, loan3, loan4]]\n",
    "axes[0, 1].bar([f'Loan {loan.loan_id}' for loan in [loan1, loan3, loan4]], risk_scores, \n",
    "               color=['lightblue', 'lightgreen', 'lightcoral'])\n",
    "axes[0, 1].set_title('Risk Scores by Loan ID')\n",
    "axes[0, 1].set_ylabel('Risk Score')\n",
    "\n",
    # 3. Monthly payments\n",
    "monthly_payments = [loan1.monthly_payment, loan2.monthly_payment, loan3.monthly_payment]\n",
    "loan_ids = [f'Loan {l.loan_id}' for l in [loan1, loan2, loan3]]\n",
    "axes[1, 0].bar(loan_ids, monthly_payments, color=sns.color_palette(\"husl\", len(monthly_payments)))\n",
    "axes[1, 0].set_title('Monthly Payments by Loan')\n",
    "axes[1, 0].set_ylabel('Monthly Payment ($)', color='black')\n",
    "\n",
    # 4. Credit score categories\n",
    "credit_scores = [loan1.credit_score, loan2.credit_score, loan3.credit_score, loan4.credit_score]\n",
    "loan_names = [f'Loan {l.loan_id}\\n({type(l).__name__})' for l in [loan1, loan2, loan3, loan4]]\n",
    "colors = ['green' if cs >= 700 else 'orange' if cs >= 650 else 'red' for cs in credit_scores]\n",
    "axes[1, 1].bar(loan_names, credit_scores, color=colors)\n",
    "axes[1, 1].set_title('Credit Scores by Loan')\n",
    "axes[1, 1].set_ylabel('Credit Score')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Querying for Data Science\n",
    "\n",
    "SQL (Structured Query Language) is essential for data science as it allows data scientists to query databases directly and efficiently extract insights from large datasets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL Querying for Data Science\n",
    "\n",
    "print(\"SQL Querying for Data Science:\")\n",
    "\n",
    "# Create a SQLite database for SQL demonstrations\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(':memory:')  # In-memory database for demonstration\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables for our lending data\n",
    "cursor.execute('''\n",
    "CREATE TABLE loans (\n",
    "    loan_id INTEGER PRIMARY KEY,\n",
    "    loan_amnt REAL,\n",
    "    int_rate REAL,\n",
    "    annual_inc REAL,\n",
    "    dti REAL,\n",
    "    fico_score INTEGER,\n",
    "    emp_length REAL,\n",
    "    loan_status INTEGER,\n",
    "    grade TEXT,\n",
    "    purpose TEXT,\n",
    "    home_ownership TEXT,\n",
    "    addr_state TEXT,\n",
    "    application_date TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# Insert our sample data\n",
    "loans_data = []\n",
    "for _, row in df.head(1000).iterrows():  # Use subset for performance\n",
    "    loans_data.append((\n",
    "        int(row['loan_id']),\n",
    "        row['loan_amnt'],\n",
    "        row['int_rate'],\n",
    "        row['annual_inc'],\n",
    "        row['dti'],\n",
    "        int(row['fico_score']),\n",
    "        row['emp_length'],\n",
    "        int(row['loan_status']),\n",
    "        str(row['grade']),\n",
    "        str(row['purpose']),\n",
    "        str(row['home_ownership']),\n",
    "        str(row['addr_state']),\n",
    "        str(row['application_date'])\n",
    "    ))\n",
    "\n",
    "cursor.executemany('''\n",
    "INSERT INTO loans VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "''', loans_data)\n",
    "conn.commit()\n",
    "\n",
    "print(\"Created SQLite database with loans table\")\n",
    "\n",
    "# 1. Basic SQL Queries\n",
    "print(\"\\n1. Basic SQL Queries:\")\n",
    "\n",
    "# SELECT queries\n",
    "query1 = \"SELECT loan_id, loan_amnt, grade, loan_status FROM loans LIMIT 5\"\n",
    "result1 = pd.read_sql_query(query1, conn)\n",
    "print(\"   Simple SELECT query:\")\n",
    "print(result1)\n",
    "\n",
    "# Aggregation queries\n",
    "query2 = \"\"\"\n",
    "SELECT \n",
    "    grade,\n",
    "    COUNT(*) as loan_count,\n",
    "    AVG(loan_amnt) as avg_loan_amount,\n",
    "    AVG(int_rate) as avg_interest_rate,\n",
    "    AVG(loan_status) as default_rate\n",
    "FROM loans \n",
    "GROUP BY grade\n",
    "ORDER BY avg_loan_amount DESC\n",
    "\"\"\"\n",
    "result2 = pd.read_sql_query(query2, conn)\n",
    "print(f\"\\n   Aggregation query (top grades by avg loan amount):\\n{result2}\")\n",
    "\n",
    "# 2. Filtering and Conditions\n",
    "print(\"\\n2. Filtering and Conditions:\")\n",
    "\n",
    "# WHERE clauses\n",
    "query3 = \"\"\"\n",
    "SELECT \n",
    "    loan_id,\n",
    "    loan_amnt,\n",
    "    fico_score,\n",
    "    int_rate,\n",
    "    loan_status\n",
    "FROM loans \n",
    "WHERE \n",
    "    fico_score > 700 \n",
    "    AND loan_amnt > 10000 \n",
    "    AND loan_status = 0\n",
    "ORDER BY loan_amnt DESC \n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "result3 = pd.read_sql_query(query3, conn)\n",
    "print(\"   Filtered query (high FICO, high amount, non-defaulted):\\n\")\n",
    "print(result3)\n",
    "\n",
    "# 3. Advanced SQL Operations\n",
    "print(\"\\n3. Advanced SQL Operations:\")\n",
    "\n",
    "# JOIN operations (creating a second table for demonstration)\n",
    "cursor.execute('''\n",
    "CREATE TABLE borrowers (\n",
    "    loan_id INTEGER PRIMARY KEY,\n",
    "    age INTEGER,\n",
    "    dependents INTEGER,\n",
    "    education TEXT,\n",
    "    employment_type TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# Insert sample borrower data\n",
    "borrower_data = []\n",
    "for loan_id in result1['loan_id'][:10]:\n",
    "    import random\n",
    "    borrower_data.append((\n",
    "        loan_id,\n",
    "        random.randint(22, 65),\n",
    "        random.randint(0, 5),\n",
    "        random.choice(['High School', 'Bachelor', 'Master', 'PhD']),\n",
    "        random.choice(['Full-time', 'Part-time', 'Self-employed', 'Contract'])\n",
    "    ))\n",
    "\n",
    "cursor.executemany('''\n",
    "INSERT INTO borrowers VALUES (?, ?, ?, ?, ?)\n",
    "''', borrower_data)\n",
    "conn.commit()\n",
    "\n",
    "# JOIN query\n",
    "query4 = \"\"\"\n",
    "SELECT \n",
    "    l.loan_id,\n",
    "    l.loan_amnt,\n",
    "    l.grade,\n",
    "    l.fico_score,\n",
    "    b.age,\n",
    "    b.education,\n",
    "    b.employment_type\n",
    "FROM loans l\n",
    "JOIN borrowers b ON l.loan_id = b.loan_id\n",
    "WHERE l.loan_amnt > 15000\n",
    "ORDER BY l.fico_score DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "result4 = pd.read_sql_query(query4, conn)\n",
    "print(\"   JOIN query (loans with borrower information):\\n\")\n",
    "print(result4)\n",
    "\n",
    "# 4. Window Functions\n",
    "print(\"\\n4. Window Functions:\")\n",
    "\n",
    "# RANK, ROW_NUMBER, LAG, LEAD functions\n",
    "query5 = \"\"\"\n",
    "SELECT \n",
    "    loan_id,\n",
    "    loan_amnt,\n",
    "    grade,\n",
    "    fico_score,\n",
    "    RANK() OVER (PARTITION BY grade ORDER BY loan_amnt DESC) as loan_amount_rank,\n",
    "    LAG(loan_amnt) OVER (ORDER BY fico_score) as prev_loan_amount\n",
    "FROM loans\n",
    "WHERE loan_amnt IS NOT NULL\n",
    "ORDER BY grade, loan_amount_rank\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "result5 = pd.read_sql_query(query5, conn)\n",
    "print(\"   Window functions query:\\n\")\n",
    "print(result5)\n",
    "\n",
    "# 5. Subqueries\n",
    "print(\"\\n5. Subqueries:\")\n",
    "\n",
    "query6 = \"\"\"\n",
    "SELECT \n",
    "    loan_id,\n",
    "    loan_amnt,\n",
    "    int_rate,\n",
    "    fico_score,\n",
    "    (SELECT AVG(loan_amnt) FROM loans) as overall_avg_loan\n",
    "FROM loans\n",
    "WHERE loan_amnt > (\n",
    "    SELECT AVG(loan_amnt) FROM loans\n",
    ") \n",
    "AND grade IN (\n",
    "    SELECT grade FROM loans \n",
    "    GROUP BY grade \n",
    "    HAVING AVG(loan_status) < 0.15\n",
    ")\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "result6 = pd.read_sql_query(query6, conn)\n",
    "print(\"   Subquery example (loans above average amount in low default grades):\\n\")\n",
    "print(result6)\n",
    "\n",
    "# 6. Common Table Expressions (CTEs)\n",
    "print(\"\\n6. Common Table Expressions (CTEs):\")\n",
    "\n",
    "query7 = \"\"\"\n",
    "WITH grade_stats AS (\n",
    "    SELECT \n",
    "        grade,\n",
    "        AVG(loan_amnt) as avg_loan,\n",
    "        AVG(int_rate) as avg_rate,\n",
    "        AVG(loan_status) as default_rate\n",
    "    FROM loans\n",
    "    GROUP BY grade\n",
    "),\n",
    "high_value_loans AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        l.loan_amnt - g.avg_loan as loan_diff_from_grade_avg\n",
    "    FROM loans l\n",
    "    JOIN grade_stats g ON l.grade = g.grade\n",
    "    WHERE l.loan_amnt > g.avg_loan\n",
    ")\n",
    "SELECT \n",
    "    grade,\n",
    "    COUNT(*) as high_value_count,\n",
    "    AVG(loan_diff_from_grade_avg) as avg_premium\n",
    "FROM high_value_loans\n",
    "GROUP BY grade\n",
    "ORDER BY avg_premium DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "result7 = pd.read_sql_query(query7, conn)\n",
    "print(\"   CTE example (high-value loans analysis):\\n\")\n",
    "print(result7)\n",
    "\n",
    "# 7. Set Operations\n",
    "print(\"\\n7. Set Operations:\")\n",
    "\n",
    "# Create additional tables for set operations\n",
    "cursor.execute('''\n",
    "CREATE TABLE approved_loans (\n",
    "    loan_id INTEGER,\n",
    "    approval_date TEXT,\n",
    "    approved_by TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# Insert some approved loan records\n",
    "approved_data = [(i, f'2022-{i%12+1:02d}-01', 'System') for i in range(1, 50)]\n",
    "cursor.executemany('INSERT INTO approved_loans VALUES (?, ?, ?)', approved_data)\n",
    "conn.commit()\n",
    "\n",
    "query8 = \"\"\"\n",
    "SELECT loan_id FROM loans WHERE grade = 'A'\n",
    "INTERSECT\n",
    "SELECT loan_id FROM approved_loans\n",
    "ORDER BY loan_id\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "result8 = pd.read_sql_query(query8, conn)\n",
    "print(\"   Set operation (INTERSECT - A-grade loans that are approved):\\n\")\n",
    "print(result8)\n",
    "\n",
    "# 8. SQL for Data Science Use Cases\n",
    "print(\"\\n8. SQL for Data Science Use Cases:\")\n",
    "\n",
    "# Cohort analysis\n",
    "query_cohort = \"\"\"\n",
    "SELECT \n",
    "    strftime('%Y-%m', application_date) as application_month,\n",
    "    COUNT(*) as total_applications,\n",
    "    AVG(loan_status) as default_rate,\n",
    "    AVG(loan_amnt) as avg_loan_amount\n",
    "FROM loans\n",
    "GROUP BY strftime('%Y-%m', application_date)\n",
    "ORDER BY application_month\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "cohort_result = pd.read_sql_query(query_cohort, conn)\n",
    "print(\"   Cohort analysis (monthly default rates and average loan amounts):\\n\")\n",
    "print(cohort_result)\n",
    "\n",
    "# Create additional features table for feature engineering\n",
    "cursor.execute('''\n",
    "CREATE TABLE loan_features AS\n",
    "SELECT \n",
    "    loan_id,\n",
    "    loan_amnt,\n",
    "    int_rate,\n",
    "    fico_score,\n",
    "    annual_inc,\n",
    "    dti,\n",
    "    loan_amnt * int_rate / 100 as interest_cost,\n",
    "    loan_amnt / (annual_inc + 1) as loan_to_income_ratio,\n",
    "    CASE \n",
    "        WHEN fico_score >= 750 THEN 'Excellent'\n",
    "        WHEN fico_score >= 700 THEN 'Good'\n",
    "        WHEN fico_score >= 650 THEN 'Fair'\n",
    "        ELSE 'Poor'\n",
    "    END as credit_category\n",
    "FROM loans\n",
    "WHERE annual_inc > 0\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "conn.commit()\n",
    "\n",
    "# Feature engineering query\n",
    "feature_query = \"\"\"\n",
    "SELECT \n",
    "    credit_category,\n",
    "    AVG(loan_to_income_ratio) as avg_loan_to_income,\n",
    "    AVG(interest_cost) as avg_interest_cost,\n",
    "    AVG(loan_status) as default_rate\n",
    "FROM loan_features f\n",
    "JOIN loans l ON f.loan_id = l.loan_id\n",
    "GROUP BY credit_category\n",
    "ORDER BY default_rate ASC\n",
    "\"\"\"\n",
    "features_result = pd.read_sql_query(feature_query, conn)\n",
    "print(f\"\\n   Feature engineering query (credit category analysis):\\n{features_result}\")\n",
    "\n",
    "# Visualize SQL results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Grade distribution from SQL query\n",
    "grade_dist = result2.set_index('grade')[['loan_count', 'avg_loan_amount']].copy()\n",
    "grade_dist.plot(kind='bar', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Loan Count and Average Amount by Grade (SQL Aggregation)')\n",
    "axes[0, 0].set_ylabel('Count / Amount')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    # 2. Default rate by grade\n",
    "axes[0, 1].bar(result2['grade'], result2['default_rate'], \n",
    "               color=sns.color_palette(\"husl\", len(result2)))\n",
    "axes[0, 1].set_title('Default Rate by Grade (SQL Aggregation)')\n",
    "axes[0, 1].set_ylabel('Default Rate')\n",
    "axes[0, 1].set_xlabel('Grade')\n",
    "\n",
    # 3. Feature engineering results\n",
    "axes[1, 0].bar(features_result['credit_category'], features_result['default_rate'], \n",
    "               color=['red', 'orange', 'green', 'darkgreen'])\n",
    "axes[1, 0].set_title('Default Rate by Credit Category (SQL Feature Engineering)')\n",
    "axes[1, 0].set_ylabel('Default Rate')\n",
    "axes[1, 0].set_xlabel('Credit Category')\n",
    "\n",
    # 4. Cohort analysis\n",
    "if len(cohort_result) > 1:\n",
    "    ax1 = axes[1, 1]\n",
    "    ax2 = ax1.twinx()  # Create a second y-axis\n",
    "    \n",
    "    line1 = ax1.plot(range(len(cohort_result)), cohort_result['default_rate'], \n",
    "                     'b-', marker='o', label='Default Rate')\n",
    "    line2 = ax2.plot(range(len(cohort_result)), cohort_result['avg_loan_amount'], \n",
    "                     'r-', marker='s', label='Avg Loan Amount')\n",
    "    \n",
    "    ax1.set_xlabel('Month')\n",
    "    ax1.set_ylabel('Default Rate', color='b')\n",
    "    ax2.set_ylabel('Avg Loan Amount', color='r')\n",
    "    ax1.set_title('Cohort Analysis: Default Rate vs Avg Loan Amount')\n",
    "    \n",
    "    # Set x-axis labels\n",
    "    ax1.set_xticks(range(len(cohort_result)))\n",
    "    ax1.set_xticklabels(cohort_result['application_month'], rotation=45)\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'Not enough data for cohort analysis', \n",
    "                    horizontalalignment='center', verticalalignment='center',\n",
    "                    transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].set_title('Cohort Analysis: Default Rate vs Avg Loan Amount')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nSQL queries demonstrate how data scientists can efficiently extract insights from large databases.\")\n",
    "print(\"These queries can be used for exploratory data analysis, feature engineering, and validation.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Use Cases in Data Science\n",
    "\n",
    "SQL is used extensively in data science for various purposes including data exploration, feature engineering, and data validation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL Use Cases in Data Science\n",
    "\n",
    "print(\"SQL Use Cases in Data Science:\")\n",
    "\n",
    "# Create a new database connection to demonstrate more SQL use cases\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the loans table again\n",
    "cursor.execute('''\n",
    "CREATE TABLE loans (\n",
    "    loan_id INTEGER PRIMARY KEY,\n",
    "    loan_amnt REAL,\n",
    "    int_rate REAL,\n",
    "    annual_inc REAL,\n",
    "    dti REAL,\n",
    "    fico_score INTEGER,\n",
    "    emp_length REAL,\n",
    "    loan_status INTEGER,\n",
    "    grade TEXT,\n",
    "    purpose TEXT,\n",
    "    home_ownership TEXT,\n",
    "    addr_state TEXT,\n",
    "    application_date TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    # Insert sample data\n",
    "loans_data = []\n",
    "for _, row in df.head(500).iterrows():\n",
    "    loans_data.append((\n",
    "        int(row['loan_id']),\n",
    "        row['loan_amnt'],\n",
    "        row['int_rate'],\n",
    "        row['annual_inc'],\n",
    "        row['dti'],\n",
    "        int(row['fico_score']),\n",
    "        row['emp_length'],\n",
    "        int(row['loan_status']),\n",
    "        str(row['grade']),\n",
    "        str(row['purpose']),\n",
    "        str(row['home_ownership']),\n",
    "        str(row['addr_state']),\n",
    "        str(row['application_date'])\n",
    "    ))\n",
    "\n",
    "cursor.executemany('INSERT INTO loans VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', loans_data)\n",
    "conn.commit()\n",
    "\n",
    "# 1. Data Exploration\n",
    "print(\"\\n1. Data Exploration with SQL:\")\n",
    "\n",
    "explore_query = \"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_records,\n",
    "    MIN(loan_amnt) as min_loan,\n",
    "    MAX(loan_amnt) as max_loan,\n",
    "    AVG(loan_amnt) as avg_loan,\n",
    "    MIN(fico_score) as min_fico,\n",
    "    MAX(fico_score) as max_fico,\n",
    "    AVG(fico_score) as avg_fico,\n",
    "    AVG(loan_status) as overall_default_rate\n",
    "FROM loans\n",
    "\"\"\"\n",
    "explore_result = pd.read_sql_query(explore_query, conn)\n",
    "print(f\"   Data exploration summary:\\n{explore_result.T if len(explore_result) == 1 else explore_result}\")\n",
    "\n",
    "# 2. Data Quality Checks\n",
    "print(\"\\n2. Data Quality Checks with SQL:\")\n",
    "\n",
    "quality_query = \"\"\"\n",
    "SELECT \n",
    "    SUM(CASE WHEN loan_amnt IS NULL THEN 1 ELSE 0 END) as null_loan_amount,\n",
    "    SUM(CASE WHEN fico_score IS NULL THEN 1 ELSE 0 END) as null_fico,\n",
    "    SUM(CASE WHEN fico_score < 300 OR fico_score > 850 THEN 1 ELSE 0 END) as invalid_fico,\n",
    "    SUM(CASE WHEN loan_amnt < 0 THEN 1 ELSE 0 END) as negative_loan,\n",
    "    SUM(CASE WHEN int_rate < 0 THEN 1 ELSE 0 END) as negative_rate,\n",
    "    SUM(CASE WHEN dti < 0 THEN 1 ELSE 0 END) as negative_dti,\n",
    "    COUNT(DISTINCT grade) as unique_grades,\n",
    "    COUNT(DISTINCT purpose) as unique_purposes\n",
    "FROM loans\n",
    "\"\"\"\n",
    "quality_result = pd.read_sql_query(quality_query, conn)\n",
    "print(f\"   Data quality checks:\\n{quality_result.T if len(quality_result) == 1 else quality_result}\")\n",
    "\n",
    "# 3. Feature Engineering\n",
    "print(\"\\n3. Feature Engineering with SQL:\")\n",
    "\n",
    "feature_eng_query = \"\"\"\n",
    "SELECT \n",
    "    loan_id,\n",
    "    loan_amnt,\n",
    "    fico_score,\n",
    "    annual_inc,\n",
    "    dti,\n",
    "    -- Create new features\n",
    "    loan_amnt / (annual_inc + 1) as loan_to_income_ratio,\n",
    "    log(loan_amnt + 1) as log_loan_amount,\n",
    "    int_rate / (fico_score / 100.0 + 1) as rate_to_fico_ratio,\n",
    "    CASE\n",
    "        WHEN emp_length > 5 THEN 'Long'\n",
    "        WHEN emp_length > 2 THEN 'Medium'\n",
    "        ELSE 'Short'\n",
    "    END as emp_length_category,\n",
    "    CASE\n",
    "        WHEN dti < 10 THEN 'Low DTI'\n",
    "        WHEN dti < 20 THEN 'Medium DTI'\n",
    "        WHEN dti < 30 THEN 'High DTI'\n",
    "        ELSE 'Very High DTI'\n",
    "    END as dti_category\n",
    "FROM loans\n",
    "WHERE annual_inc > 0\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "feature_result = pd.read_sql_query(feature_eng_query, conn)\n",
    "print(\"   Feature engineering results (first 20 records):\\n\")\n",
    "print(feature_result)\n",
    "\n",
    "# 4. Statistical Analysis\n",
    "print(\"\\n4. Statistical Analysis with SQL:\")\n",
    "\n",
    "stats_query = \"\"\"\n",
    "SELECT \n",
    "    purpose,\n",
    "    COUNT(*) as loan_count,\n",
    "    AVG(loan_amnt) as avg_loan,\n",
    "    AVG(fico_score) as avg_fico,\n",
    "    AVG(int_rate) as avg_rate,\n",
    "    AVG(loan_status) as default_rate,\n",
    "    MAX(loan_amnt) as max_loan,\n",
    "    MIN(loan_amnt) as min_loan,\n",
    "    COUNT(*) * 100.0 / (SELECT COUNT(*) FROM loans) as percentage_of_total\n",
    "FROM loans\n",
    "GROUP BY purpose\n",
    "HAVING COUNT(*) > 10  -- Only include purposes with more than 10 loans\n",
    "ORDER BY default_rate DESC\n",
    "\"\"\"\n",
    "stats_result = pd.read_sql_query(stats_query, conn)\n",
    "print(\"   Statistical analysis by loan purpose:\\n\")\n",
    "print(stats_result)\n",
    "\n",
    "# 5. Hypothesis Testing (Conceptual with SQL)\n",
    "print(\"\\n5. Hypothesis Testing Concept with SQL:\")\n",
    "\n",
    "# Testing if there's a significant difference in default rates between grades\n",
    "hypothesis_query = \"\"\"\n",
    "SELECT \n",
    "    grade,\n",
    "    COUNT(*) as total_loans,\n",
    "    SUM(loan_status) as defaulted_loans,\n",
    "    AVG(loan_status) as default_rate,\n",
    "    AVG(fico_score) as avg_fico,\n",
    "    AVG(loan_amnt) as avg_loan_amnt\n",
    "FROM loans\n",
    "GROUP BY grade\n",
    "ORDER BY default_rate DESC\n",
    "\"\"\"\n",
    "hypothesis_result = pd.read_sql_query(hypothesis_query, conn)\n",
    "print(\"   Default rates by grade (hypothesis: higher grades = lower default rates):\\n\")\n",
    "print(hypothesis_result)\n",
    "\n",
    "# 6. Data Sampling\n",
    "print(\"\\n6. Data Sampling with SQL:\")\n",
    "\n",
    "# Simple random sampling\n",
    "sampling_query = \"\"\"\n",
    "SELECT \n",
    "    loan_id, loan_amnt, fico_score, int_rate, loan_status\n",
    "FROM loans\n",
    "WHERE RANDOM() % 100 < 5  -- Random sample of ~5% of records\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "sampling_result = pd.read_sql_query(sampling_query, conn)\n",
    "print(\"   Random sample of loans (5% of data):\\n\")\n",
    "print(sampling_result)\n",
    "\n",
    "# Stratified sampling by grade\n",
    "stratified_query = \"\"\"\n",
    "WITH grade_counts AS (\n",
    "    SELECT \n",
    "        grade,\n",
    "        COUNT(*) as total_count,\n",
    "        CAST(COUNT(*) * 0.1 AS INTEGER) as sample_size  -- 10% of each grade\n",
    "    FROM loans\n",
    "    GROUP BY grade\n",
    "),\n",
    "ranked_loans AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        ROW_NUMBER() OVER (PARTITION BY grade ORDER BY RANDOM()) as rn\n",
    "    FROM loans\n",
    ")\n",
    "SELECT \n",
    "    r.loan_id, r.loan_amnt, r.fico_score, r.grade, r.loan_status\n",
    "FROM ranked_loans r\n",
    "JOIN grade_counts g ON r.grade = g.grade\n",
    "WHERE r.rn <= g.sample_size\n",
    "ORDER BY r.grade\n",
    "LIMIT 30\n",
    "\"\"\"\n",
    "stratified_result = pd.read_sql_query(stratified_query, conn)\n",
    "print(f\"\\n   Stratified sample by grade (10% of each grade):\\n\")\n",
    "print(stratified_result)\n",
    "\n",
    "# 7. Time Series Analysis\n",
    "print(\"\\n7. Time Series Analysis with SQL:\")\n",
    "\n",
    "timeseries_query = \"\"\"\n",
    "SELECT \n",
    "    strftime('%Y-%m', application_date) as month,\n",
    "    COUNT(*) as application_count,\n",
    "    AVG(loan_amnt) as avg_loan_amount,\n",
    "    AVG(fico_score) as avg_fico_score,\n",
    "    AVG(loan_status) as monthly_default_rate,\n",
    "    SUM(loan_amnt) as total_volume\n",
    "FROM loans\n",
    "GROUP BY strftime('%Y-%m', application_date)\n",
    "ORDER BY month\n",
    "LIMIT 12\n",
    "\"\"\"\n",
    "timeseries_result = pd.read_sql_query(timeseries_query, conn)\n",
    "print(\"   Time series analysis (monthly aggregations):\\n\")\n",
    "print(timeseries_result)\n",
    "\n",
    "# 8. Data Validation\n",
    "print(\"\\n8. Data Validation with SQL:\")\n",
    "\n",
    "validation_query = \"\"\"\n",
    "SELECT \n",
    "    'Total Records' as validation_type,\n",
    "    COUNT(*) as value\n",
    "FROM loans\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    'Avg FICO Score' as validation_type,\n",
    "    AVG(fico_score) as value\n",
    "FROM loans\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    'Avg Interest Rate' as validation_type,\n",
    "    AVG(int_rate) as value\n",
    "FROM loans\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    'Default Rate' as validation_type,\n",
    "    AVG(loan_status) as value\n",
    "FROM loans\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    'Avg DTI' as validation_type,\n",
    "    AVG(dti) as value\n",
    "FROM loans\n",
    "\"\"\"\n",
    "validation_result = pd.read_sql_query(validation_query, conn)\n",
    "print(\"   Data validation summary:\\n\")\n",
    "print(validation_result)\n",
    "\n",
    # Close database connection\n",
    "conn.close()\n",
    "\n",
    # Visualize SQL use cases\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Quality check results visualization\n",
    "quality_data = quality_result.iloc[0]\n",
    "quality_cols = ['null_loan_amount', 'null_fico', 'invalid_fico', 'negative_loan', 'negative_rate', 'negative_dti']\n",
    "quality_values = [quality_data[col] for col in quality_cols if col in quality_data.index]\n",
    "quality_names = [col.replace('_', ' ').title() for col in quality_cols if col in quality_data.index]\n",
    "axes[0, 0].bar(quality_names, quality_values, color=['red' if v > 0 else 'green' for v in quality_values])\n",
    "axes[0, 0].set_title('Data Quality Issues')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Default rates by purpose\n",
    "if len(stats_result) > 0:\n",
    "    axes[0, 1].bar(stats_result['purpose'], stats_result['default_rate'], \n",
    "                   color=sns.color_palette(\"husl\", len(stats_result)))\n",
    "    axes[0, 1].set_title('Default Rate by Purpose')\n",
    "    axes[0, 1].set_ylabel('Default Rate')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "else:\n",
    "    axes[0, 1].text(0.5, 0.5, 'No data for default rates by purpose', \n",
    "                    horizontalalignment='center', verticalalignment='center',\n",
    "                    transform=axes[0, 1].transAxes)\n",
    "    axes[0, 1].set_title('Default Rate by Purpose')\n",
    "\n",
    "# 3. Hypothesis testing results\n",
    "if len(hypothesis_result) > 0:\n",
    "    axes[1, 0].plot(hypothesis_result['grade'], hypothesis_result['default_rate'], \n",
    "                    marker='o', linewidth=2, markersize=8)\n",
    "    axes[1, 0].set_title('Default Rate by Grade (Hypothesis Testing)')\n",
    "    axes[1, 0].set_ylabel('Default Rate')\n",
    "    axes[1, 0].set_xlabel('Grade')\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'No data for hypothesis testing', \n",
    "                    horizontalalignment='center', verticalalignment='center',\n",
    "                    transform=axes[1, 0].transAxes)\n",
    "    axes[1, 0].set_title('Default Rate by Grade (Hypothesis Testing)')\n",
    "\n",
    "# 4. Time series visualization\n",
    "if len(timeseries_result) > 0:\n",
    "    ax1 = axes[1, 1]\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    line1 = ax1.plot(range(len(timeseries_result)), timeseries_result['application_count'], \n",
    "                     'b-', marker='o', label='Applications')\n",
    "    line2 = ax2.plot(range(len(timeseries_result)), timeseries_result['total_volume'], \n",
    "                     'r-', marker='s', label='Total Volume')\n",
    "    \n",
    "    ax1.set_xlabel('Time Period')\n",
    "    ax1.set_ylabel('Application Count', color='b')\n",
    "    ax2.set_ylabel('Total Volume', color='r')\n",
    "    ax1.set_title('Time Series: Applications vs Volume')\n",
    "    \n",
    "    # Set x-axis labels\n",
    "    ax1.set_xticks(range(len(timeseries_result)))\n",
    "    ax1.set_xticklabels(timeseries_result['month'], rotation=45)\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'No time series data', \n",
    "                    horizontalalignment='center', verticalalignment='center',\n",
    "                    transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].set_title('Time Series: Applications vs Volume')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSQL is essential for data science workflows because it allows for:\")\n",
    "print(\"1. Efficient data exploration and summary statistics\")\n",
    "print(\"2. Data quality validation and cleaning\")\n",
    "print(\"3. Feature engineering and transformation\")\n",
    "print(\"4. Statistical analysis and hypothesis testing\")\n",
    "print(\"5. Data sampling for modeling\")\n",
    "print(\"6. Time series analysis\")\n",
    "print(\"7. Data validation and monitoring\")\n",
    "print(\"8. Integration with production databases\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this comprehensive notebook on programming language (Python) and SQL querying for data science, we've explored:\n",
    "\n",
    "1. **Python for Data Science**: The fundamental data manipulation, visualization, and analysis capabilities that make Python a premier choice for data scientists.\n",
    "\n",
    "2. **CRUD Operations in Python**: How to Create, Read, Update, and Delete data using pandas and other Python libraries.\n",
    "\n",
    "3. **Data Frame Operations**: Essential operations for working with tabular data including selection, filtering, grouping, and aggregation.\n",
    "\n",
    "4. **Table Operations in Python**: Advanced operations like pivot tables, cross-tabulations, reshaping, and complex calculations.\n",
    "\n",
    "5. **Match Operations**: Techniques for finding and comparing data across different datasets, using exact matching, fuzzy matching, and conditional matching.\n",
    "\n",
    "6. **Import/Export Operations**: Critical for data science workflows, allowing data to be read from and written to various formats and sources.\n",
    "\n",
    "7. **Functions and Classes in Python**: How Python's functional and object-oriented programming capabilities enable code reusability, organization, and abstraction.\n",
    "\n",
    "8. **Object-Oriented Programming (OOP) in Python**: Concepts of classes, inheritance, encapsulation, and polymorphism applied to data science scenarios.\n",
    "\n",
    "9. **SQL Querying for Data Science**: How SQL enables data scientists to efficiently query databases and extract insights from large datasets.\n",
    "\n",
    "10. **SQL Use Cases in Data Science**: Practical applications of SQL in data exploration, quality checks, feature engineering, statistical analysis, and more.\n",
    "\n",
    "These programming and querying skills form the foundation of effective data science practice. They enable data scientists to efficiently manipulate, analyze, and extract insights from complex datasets like the Lending Club data used throughout this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 }
}